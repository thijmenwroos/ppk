{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of some chemprop warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('/home/s2861704/ppk/test_kin/prep_storage/K200_EGFR_TEST.csv')\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the dataframe to have the accession as columns\n",
    "df = df.pivot(index=\"SMILES\", columns=\"accession\", values=\"pchembl_value_Mean\")\n",
    "#df.columns.name = None\n",
    "df.reset_index(inplace=True)\n",
    "print(df.columns)\n",
    "\n",
    "display(df.head())\n",
    "#Teams message + delete smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df))\n",
    "# max_Nans = len(df) - 30\n",
    "# print(max_Nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_noempty = df\n",
    "# df_noempty = df_noempty.drop(list(df.columns[df.isna().sum() > max_Nans]), axis=1)\n",
    "# df = df_noempty.copy()\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = list(df.columns)\n",
    "print (column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del column_list[0:1]\n",
    "print(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data import QSPRDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "target_props = []\n",
    "for target in column_list:\n",
    "    target_props.append({'name': target, 'task': \"REGRESSION\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_kinase200 = df.columns[1:7].tolist()\n",
    "display(targets_kinase200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data import QSPRDataset, RandomSplit\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.data.descriptors.sets import SmilesDesc\n",
    "from qsprpred.data.sampling.splits import GBMTRandomSplit, GBMTDataSplit\n",
    "from split import random_global_equilibrated_random_split, dissimilaritydrive_global_balanced_cluster_split\n",
    "\n",
    "df = dissimilaritydrive_global_balanced_cluster_split(data=df, targets=targets_kinase200, threads=8, sizes = [0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "print(df['split'].unique())\n",
    "print(len(df[df['split']==0]))\n",
    "print(len(df[df['split']=='train']))\n",
    "print(len(df[df['split']=='test']))\n",
    "df.to_csv(path_or_buf='/home/s2861704/ppk/test_kin/test_output/test_split.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload packages for df reload\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from qsprpred.data import QSPRDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "from qsprpred.data import QSPRDataset, RandomSplit\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.data.descriptors.sets import SmilesDesc\n",
    "from qsprpred.data.sampling.splits import GBMTRandomSplit, GBMTDataSplit\n",
    "from split import random_global_equilibrated_random_split, dissimilaritydrive_global_balanced_cluster_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'P00533', 'task': 'REGRESSION'}, {'name': 'P04626', 'task': 'REGRESSION'}, {'name': 'P17948', 'task': 'REGRESSION'}, {'name': 'P35916', 'task': 'REGRESSION'}, {'name': 'P35968', 'task': 'REGRESSION'}, {'name': 'Q15303', 'task': 'REGRESSION'}]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/home/s2861704/ppk/test_kin/test_output/test_split.csv', sep=',')\n",
    "\n",
    "column_list = list(df.columns[1:7])\n",
    "# del column_list[0:1]\n",
    "target_props = []\n",
    "for target in column_list:\n",
    "    target_props.append({'name': target, 'task': \"REGRESSION\"})\n",
    "print(target_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>P00533</th>\n",
       "      <th>P04626</th>\n",
       "      <th>P17948</th>\n",
       "      <th>P35916</th>\n",
       "      <th>P35968</th>\n",
       "      <th>Q15303</th>\n",
       "      <th>QSPRID</th>\n",
       "      <th>P00533_original</th>\n",
       "      <th>P04626_original</th>\n",
       "      <th>P17948_original</th>\n",
       "      <th>P35916_original</th>\n",
       "      <th>P35968_original</th>\n",
       "      <th>Q15303_original</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSPRID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00000</th>\n",
       "      <td>Brc1cc2c(NCc3ccccc3)ncnc2s1</td>\n",
       "      <td>6.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00000</td>\n",
       "      <td>6.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00001</th>\n",
       "      <td>Brc1cc2c(NCc3ccccn3)ncnc2s1</td>\n",
       "      <td>5.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00001</td>\n",
       "      <td>5.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00002</th>\n",
       "      <td>Brc1cc2c(NCc3cccs3)ncnc2s1</td>\n",
       "      <td>5.860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00002</td>\n",
       "      <td>5.860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00003</th>\n",
       "      <td>Brc1cc2c(NCc3ccncc3)ncnc2s1</td>\n",
       "      <td>5.410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00003</td>\n",
       "      <td>5.410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00004</th>\n",
       "      <td>Brc1cc2c(Nc3ccccc3)ncnc2s1</td>\n",
       "      <td>7.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00004</td>\n",
       "      <td>7.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_13855</th>\n",
       "      <td>c1csc(-c2n[nH]c3c2Cc2ccccc2-3)c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_13855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_13856</th>\n",
       "      <td>c1csc(-c2nnc(Cc3nc4ccccc4[nH]3)o2)c1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_13856</td>\n",
       "      <td>4.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_13857</th>\n",
       "      <td>c1nc(Nc2ccc3[nH]ccc3c2)c2sc(-c3ccc(NCCN4CCCC4)...</td>\n",
       "      <td>9.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_13857</td>\n",
       "      <td>9.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_13858</th>\n",
       "      <td>c1nc(Nc2ccc3[nH]ccc3c2)c2sccc2n1</td>\n",
       "      <td>6.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_13858</td>\n",
       "      <td>6.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_13859</th>\n",
       "      <td>c1nc(Nc2ccc3[nH]ncc3c2)c2nc(N3CCOCC3)ncc2n1</td>\n",
       "      <td>6.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_13859</td>\n",
       "      <td>6.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13860 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        SMILES  \\\n",
       "QSPRID                                                                           \n",
       "ChempropMTTestDataset_00000                        Brc1cc2c(NCc3ccccc3)ncnc2s1   \n",
       "ChempropMTTestDataset_00001                        Brc1cc2c(NCc3ccccn3)ncnc2s1   \n",
       "ChempropMTTestDataset_00002                         Brc1cc2c(NCc3cccs3)ncnc2s1   \n",
       "ChempropMTTestDataset_00003                        Brc1cc2c(NCc3ccncc3)ncnc2s1   \n",
       "ChempropMTTestDataset_00004                         Brc1cc2c(Nc3ccccc3)ncnc2s1   \n",
       "...                                                                        ...   \n",
       "ChempropMTTestDataset_13855                   c1csc(-c2n[nH]c3c2Cc2ccccc2-3)c1   \n",
       "ChempropMTTestDataset_13856               c1csc(-c2nnc(Cc3nc4ccccc4[nH]3)o2)c1   \n",
       "ChempropMTTestDataset_13857  c1nc(Nc2ccc3[nH]ccc3c2)c2sc(-c3ccc(NCCN4CCCC4)...   \n",
       "ChempropMTTestDataset_13858                   c1nc(Nc2ccc3[nH]ccc3c2)c2sccc2n1   \n",
       "ChempropMTTestDataset_13859        c1nc(Nc2ccc3[nH]ncc3c2)c2nc(N3CCOCC3)ncc2n1   \n",
       "\n",
       "                             P00533  P04626  P17948  P35916  P35968  Q15303  \\\n",
       "QSPRID                                                                        \n",
       "ChempropMTTestDataset_00000   6.620     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00001   5.100     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00002   5.860     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00003   5.410     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00004   7.100     NaN     NaN     NaN     NaN     NaN   \n",
       "...                             ...     ...     ...     ...     ...     ...   \n",
       "ChempropMTTestDataset_13855     NaN     NaN     NaN     NaN    6.03     NaN   \n",
       "ChempropMTTestDataset_13856   4.000     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_13857   9.000     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_13858   6.222     NaN     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_13859   6.903     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "                                                  QSPRID  P00533_original  \\\n",
       "QSPRID                                                                      \n",
       "ChempropMTTestDataset_00000  ChempropMTTestDataset_00000            6.620   \n",
       "ChempropMTTestDataset_00001  ChempropMTTestDataset_00001            5.100   \n",
       "ChempropMTTestDataset_00002  ChempropMTTestDataset_00002            5.860   \n",
       "ChempropMTTestDataset_00003  ChempropMTTestDataset_00003            5.410   \n",
       "ChempropMTTestDataset_00004  ChempropMTTestDataset_00004            7.100   \n",
       "...                                                  ...              ...   \n",
       "ChempropMTTestDataset_13855  ChempropMTTestDataset_13855              NaN   \n",
       "ChempropMTTestDataset_13856  ChempropMTTestDataset_13856            4.000   \n",
       "ChempropMTTestDataset_13857  ChempropMTTestDataset_13857            9.000   \n",
       "ChempropMTTestDataset_13858  ChempropMTTestDataset_13858            6.222   \n",
       "ChempropMTTestDataset_13859  ChempropMTTestDataset_13859            6.903   \n",
       "\n",
       "                             P04626_original  P17948_original  \\\n",
       "QSPRID                                                          \n",
       "ChempropMTTestDataset_00000              NaN              NaN   \n",
       "ChempropMTTestDataset_00001              NaN              NaN   \n",
       "ChempropMTTestDataset_00002              NaN              NaN   \n",
       "ChempropMTTestDataset_00003              NaN              NaN   \n",
       "ChempropMTTestDataset_00004              NaN              NaN   \n",
       "...                                      ...              ...   \n",
       "ChempropMTTestDataset_13855              NaN              NaN   \n",
       "ChempropMTTestDataset_13856              NaN              NaN   \n",
       "ChempropMTTestDataset_13857              NaN              NaN   \n",
       "ChempropMTTestDataset_13858              NaN              NaN   \n",
       "ChempropMTTestDataset_13859              NaN              NaN   \n",
       "\n",
       "                             P35916_original  P35968_original  \\\n",
       "QSPRID                                                          \n",
       "ChempropMTTestDataset_00000              NaN              NaN   \n",
       "ChempropMTTestDataset_00001              NaN              NaN   \n",
       "ChempropMTTestDataset_00002              NaN              NaN   \n",
       "ChempropMTTestDataset_00003              NaN              NaN   \n",
       "ChempropMTTestDataset_00004              NaN              NaN   \n",
       "...                                      ...              ...   \n",
       "ChempropMTTestDataset_13855              NaN             6.03   \n",
       "ChempropMTTestDataset_13856              NaN              NaN   \n",
       "ChempropMTTestDataset_13857              NaN              NaN   \n",
       "ChempropMTTestDataset_13858              NaN              NaN   \n",
       "ChempropMTTestDataset_13859              NaN              NaN   \n",
       "\n",
       "                             Q15303_original  split  \n",
       "QSPRID                                               \n",
       "ChempropMTTestDataset_00000              NaN  train  \n",
       "ChempropMTTestDataset_00001              NaN  train  \n",
       "ChempropMTTestDataset_00002              NaN  train  \n",
       "ChempropMTTestDataset_00003              NaN  train  \n",
       "ChempropMTTestDataset_00004              NaN  train  \n",
       "...                                      ...    ...  \n",
       "ChempropMTTestDataset_13855              NaN   test  \n",
       "ChempropMTTestDataset_13856              NaN   test  \n",
       "ChempropMTTestDataset_13857              NaN  train  \n",
       "ChempropMTTestDataset_13858              NaN  train  \n",
       "ChempropMTTestDataset_13859              NaN  train  \n",
       "\n",
       "[13860 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = QSPRDataset(\n",
    "    name=\"ChempropMTTestDataset\",\n",
    "    df=df,\n",
    "    target_props=target_props,\n",
    "    store_dir=\"/home/s2861704/ppk/test_kin/test_output/MT/data\",\n",
    "    random_state=42,\n",
    "    drop_empty=False,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "dataset.getDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>P00533</th>\n",
       "      <th>P04626</th>\n",
       "      <th>P17948</th>\n",
       "      <th>P35916</th>\n",
       "      <th>P35968</th>\n",
       "      <th>Q15303</th>\n",
       "      <th>QSPRID</th>\n",
       "      <th>P00533_original</th>\n",
       "      <th>P04626_original</th>\n",
       "      <th>P17948_original</th>\n",
       "      <th>P35916_original</th>\n",
       "      <th>P35968_original</th>\n",
       "      <th>Q15303_original</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSPRID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00000</th>\n",
       "      <td>Brc1cc2c(NCc3ccccc3)ncnc2s1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00000</td>\n",
       "      <td>6.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00001</th>\n",
       "      <td>Brc1cc2c(NCc3ccccn3)ncnc2s1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00001</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00002</th>\n",
       "      <td>Brc1cc2c(NCc3cccs3)ncnc2s1</td>\n",
       "      <td>5.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00002</td>\n",
       "      <td>5.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00003</th>\n",
       "      <td>Brc1cc2c(NCc3ccncc3)ncnc2s1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00003</td>\n",
       "      <td>5.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropMTTestDataset_00004</th>\n",
       "      <td>Brc1cc2c(Nc3ccccc3)ncnc2s1</td>\n",
       "      <td>7.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChempropMTTestDataset_00004</td>\n",
       "      <td>7.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SMILES  P00533  P04626  \\\n",
       "QSPRID                                                                     \n",
       "ChempropMTTestDataset_00000  Brc1cc2c(NCc3ccccc3)ncnc2s1    6.62     NaN   \n",
       "ChempropMTTestDataset_00001  Brc1cc2c(NCc3ccccn3)ncnc2s1    5.10     NaN   \n",
       "ChempropMTTestDataset_00002   Brc1cc2c(NCc3cccs3)ncnc2s1    5.86     NaN   \n",
       "ChempropMTTestDataset_00003  Brc1cc2c(NCc3ccncc3)ncnc2s1    5.41     NaN   \n",
       "ChempropMTTestDataset_00004   Brc1cc2c(Nc3ccccc3)ncnc2s1    7.10     NaN   \n",
       "\n",
       "                             P17948  P35916  P35968  Q15303  \\\n",
       "QSPRID                                                        \n",
       "ChempropMTTestDataset_00000     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00001     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00002     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00003     NaN     NaN     NaN     NaN   \n",
       "ChempropMTTestDataset_00004     NaN     NaN     NaN     NaN   \n",
       "\n",
       "                                                  QSPRID  P00533_original  \\\n",
       "QSPRID                                                                      \n",
       "ChempropMTTestDataset_00000  ChempropMTTestDataset_00000             6.62   \n",
       "ChempropMTTestDataset_00001  ChempropMTTestDataset_00001             5.10   \n",
       "ChempropMTTestDataset_00002  ChempropMTTestDataset_00002             5.86   \n",
       "ChempropMTTestDataset_00003  ChempropMTTestDataset_00003             5.41   \n",
       "ChempropMTTestDataset_00004  ChempropMTTestDataset_00004             7.10   \n",
       "\n",
       "                             P04626_original  P17948_original  \\\n",
       "QSPRID                                                          \n",
       "ChempropMTTestDataset_00000              NaN              NaN   \n",
       "ChempropMTTestDataset_00001              NaN              NaN   \n",
       "ChempropMTTestDataset_00002              NaN              NaN   \n",
       "ChempropMTTestDataset_00003              NaN              NaN   \n",
       "ChempropMTTestDataset_00004              NaN              NaN   \n",
       "\n",
       "                             P35916_original  P35968_original  \\\n",
       "QSPRID                                                          \n",
       "ChempropMTTestDataset_00000              NaN              NaN   \n",
       "ChempropMTTestDataset_00001              NaN              NaN   \n",
       "ChempropMTTestDataset_00002              NaN              NaN   \n",
       "ChempropMTTestDataset_00003              NaN              NaN   \n",
       "ChempropMTTestDataset_00004              NaN              NaN   \n",
       "\n",
       "                             Q15303_original  split  \n",
       "QSPRID                                               \n",
       "ChempropMTTestDataset_00000              NaN  train  \n",
       "ChempropMTTestDataset_00001              NaN  train  \n",
       "ChempropMTTestDataset_00002              NaN  train  \n",
       "ChempropMTTestDataset_00003              NaN  train  \n",
       "ChempropMTTestDataset_00004              NaN  train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_calculators = [SmilesDesc(), MorganFP(radius=3, nBits=2048)]\n",
    "dataset.prepareDataset(\n",
    "    # split=random_global_equilibrated_random_split(data=df, targets=targets_kinase200, seed=2025),\n",
    "    feature_calculators=feature_calculators,\n",
    "    recalculate_features=True,\n",
    ")\n",
    "\n",
    "dataset.getDF().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no_cuda': 'Turn off cuda (i.e., use CPU instead of GPU).',\n",
       " 'gpu': 'Which GPU to use.',\n",
       " 'num_workers': 'Number of workers for the parallel data loading (0 means sequential).',\n",
       " 'batch_size': 'Batch size.',\n",
       " 'no_cache_mol': 'Whether to not cache the RDKit molecule for each SMILES string to reduce memory usage (cached by default).',\n",
       " 'empty_cache': 'Whether to empty all caches before training or predicting. This is necessary if multiple jobs are run within a single script and the atom or bond features change.',\n",
       " 'loss_function': 'Choice of loss function. Loss functions are limited to compatible dataset types.',\n",
       " 'metric': \"Metric to use with the validation set for early stopping. Defaults to 'auc' for classification, 'rmse' for regression. Note. In Chemprop this metric is also used for test-set evaluation, but in QSPRpred this is determined by the scoring parameter in assessment.\",\n",
       " 'bias': 'Whether to add bias to linear layers.',\n",
       " 'hidden_size': 'Dimensionality of hidden layers in MPN.',\n",
       " 'depth': 'Number of message passing steps.',\n",
       " 'mpn_shared': \"Whether to use the same message passing neural network for all input molecule Only relevant if 'number_of_molecules > 1'\",\n",
       " 'dropout': 'Dropout probability.',\n",
       " 'activation': 'Activation function.',\n",
       " 'atom_messages': 'Centers messages on atoms instead of on bonds.',\n",
       " 'undirected': 'Undirected edges (always sum the two relevant bond vectors).',\n",
       " 'ffn_hidden_size': 'Hidden dim for higher-capacity FFN (defaults to hidden_size).',\n",
       " 'ffn_num_layers': 'Number of layers in FFN after MPN encoding.',\n",
       " 'epochs': 'Number of epochs to run.',\n",
       " 'warmup_epochs': \"Number of epochs during which learning rate increases linearly from 'init_lr' to 'max_lr'. Afterwards, learning rate decreases exponentially from 'max_lr' to 'final_lr'.\",\n",
       " 'init_lr': 'Initial learning rate.',\n",
       " 'max_lr': 'Maximum learning rate.',\n",
       " 'final_lr': 'Final learning rate.',\n",
       " 'grad_clip': 'Maximum magnitude of gradient during training.',\n",
       " 'class_balance': 'Trains with an equal number of positives and negatives in each batch.',\n",
       " 'evidential_regularization': 'Value used in regularization for evidential loss function. The default value recommended by Soleimany et al.(2021) is 0.2. Optimal value is dataset-dependent; it is recommended that users test different values to find the best value for their model.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qsprpred.extra.gpu.models.chemprop import ChempropModel\n",
    "\n",
    "ChempropModel.getAvailableParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2861704/.conda/envs/drugex_env/lib/python3.12/site-packages/chemprop/utils.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "/home/s2861704/.conda/envs/drugex_env/lib/python3.12/site-packages/chemprop/utils.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "/home/s2861704/.conda/envs/drugex_env/lib/python3.12/site-packages/chemprop/utils.py:473: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vars(torch.load(path, map_location=lambda storage, loc: storage)[\"args\"]),\n",
      "qsprpred - WARNING - Explicitly specified parameters ({'epochs': 5})will override model settings read from file: {'epochs': 5, 'data_path': '', 'dataset_type': 'regression', 'metric': 'rmse', 'explicit_h': False, 'ignore_columns': None, 'aggregation': 'mean', 'no_cache_mol': False, 'crossval_index_sets': None, 'separate_test_features_path': None, 'num_folds': 1, 'bond_targets': [], 'quiet': False, 'separate_val_atom_descriptors_path': None, 'metrics': ['rmse'], 'separate_val_constraints_path': None, 'atom_descriptors_path': None, 'weights_ffn_num_layers': 2, 'separate_val_phase_features_path': None, 'atom_descriptors': None, 'features_path': None, 'show_individual_scores': False, 'separate_test_phase_features_path': None, 'separate_test_constraints_path': None, 'shared_atom_bond_ffn': True, 'depth_solvent': 3, 'checkpoint_path': None, 'save_smiles_splits': False, 'separate_val_features_path': None, 'device': device(type='cuda', index=0), 'features_scaling': True, 'depth': 3, 'bond_descriptor_scaling': True, 'save_dir': '/tmp/tmpjsclkn3o', 'separate_test_path': None, 'test': False, 'use_input_features': False, 'overwrite_default_bond_features': False, 'seed': 0, 'reaction': False, 'features_size': None, 'mpn_shared': False, 'features_only': False, 'dropout': 0.0, 'freeze_first_only': False, 'warmup_epochs': 2.0, 'split_key_molecule': 0, 'empty_cache': False, 'ensemble_size': 1, 'features_generator': None, 'save_preds': False, 'split_sizes': [0.8, 0.1, 0.1], 'aggregation_norm': 100, 'multiclass_num_classes': 3, 'num_lrs': 1, 'smiles_columns': [None], 'checkpoint_frzn': None, 'hidden_size': 300, 'evidential_regularization': 0, 'no_cuda': False, 'split_type': 'random', 'crossval_index_dir': None, 'no_shared_atom_bond_ffn': False, 'separate_val_bond_descriptors_path': None, 'bond_descriptors': None, 'spectra_activation': 'exp', 'no_bond_descriptor_scaling': False, 'bond_features_size': 0, 'grad_clip': None, 'checkpoint_dir': None, 'folds_file': None, 'no_adding_bond_types': False, 'number_of_molecules': 1, 'target_weights': None, 'test_fold_index': None, 'num_workers': 8, 'undirected': False, 'frzn_ffn_layers': 0, 'bond_descriptors_size': 0, 'atom_features_size': 0, 'minimize_score': True, 'num_tasks': 6, 'atom_descriptor_scaling': True, 'data_weights_path': None, 'adding_bond_types': True, 'init_lr': 0.0001, 'is_atom_bond_targets': False, 'bias': False, 'extra_metrics': [], 'target_columns': None, 'pytorch_seed': 0, 'atom_messages': False, 'no_atom_descriptor_scaling': False, 'spectra_target_floor': 1e-08, 'atom_targets': [], 'batch_size': 50, 'constraints_path': None, 'keeping_atom_map': False, 'activation': 'ReLU', 'reaction_solvent': False, 'separate_test_bond_descriptors_path': None, 'loss_function': 'mse', 'ffn_num_layers': 2, 'no_features_scaling': False, 'config_path': None, 'hidden_size_solvent': 300, 'checkpoint_paths': None, 'task_names': ['P00533', 'P04626', 'P17948', 'P35916', 'P35968', 'Q15303'], 'gpu': 0, 'overwrite_default_atom_features': False, 'phase_features_path': None, 'cuda': True, 'max_data_size': None, 'spectra_phase_mask': False, 'ffn_hidden_size': 300, 'cache_cutoff': 10000, 'crossval_index_file': None, 'atom_constraints': [], 'separate_val_path': None, 'spectra_phase_mask_path': None, 'class_balance': False, 'reaction_mode': 'reac_diff', 'atom_descriptors_size': 0, 'adding_h': False, 'bias_solvent': False, 'final_lr': 0.0001, 'val_fold_index': None, 'bond_constraints': [], 'bond_descriptors_path': None, 'resume_experiment': False, 'separate_test_atom_descriptors_path': None, 'log_frequency': 10, 'max_lr': 0.001, 'train_data_size': 13860}.Estimator will be reloaded with the new parameters and will have to be re-fitted if fitted previously.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "os.makedirs(\"/home/s2861704/ppk/test_kin/test_output/MT/models\", exist_ok=True)\n",
    "model = ChempropModel(\n",
    "    base_dir='/home/s2861704/ppk/test_kin/test_output/MT/models',\n",
    "    name='ChempropMTTestModel',\n",
    "    parameters={\"epochs\": 5},\n",
    "    quiet_logger=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.models import SklearnMetrics, MaskedMetric\n",
    "from qsprpred.plotting import regression\n",
    "from qsprpred.tasks import ModelTasks\n",
    "import numpy as np\n",
    "\n",
    "r2_score=SklearnMetrics('r2')\n",
    "masked_metric=MaskedMetric(metric=SklearnMetrics('r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from qsprpred.models.assessment.metrics.scikit_learn import SklearnMetrics\n",
    "from qsprpred.data import QSPRDataset\n",
    "from qsprpred.data.sampling.splits import DataSplit\n",
    "from qsprpred.logs import logger\n",
    "from qsprpred.models.early_stopping import EarlyStoppingMode\n",
    "from qsprpred.models.model import QSPRModel\n",
    "from qsprpred.models.monitors import AssessorMonitor, BaseMonitor\n",
    "\n",
    "class ModelAssessor(ABC):\n",
    "    \"\"\"Base class for assessment methods.\n",
    "\n",
    "    Attributes:\n",
    "        scoreFunc (Metric): scoring function to use, should match the output of the\n",
    "                        evaluation method (e.g. if the evaluation methods returns\n",
    "                        class probabilities, the scoring function support class\n",
    "                        probabilities)\n",
    "        monitor (AssessorMonitor): monitor to use for assessment, if None, a BaseMonitor\n",
    "            is used\n",
    "        useProba (bool): use probabilities for classification models\n",
    "        mode (EarlyStoppingMode): early stopping mode for fitting\n",
    "        splitMultitaskScores (bool): whether to split the scores per task for multitask models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            scoring: str | Callable[[Iterable, Iterable], float],\n",
    "            monitor: AssessorMonitor | None = None,\n",
    "            use_proba: bool = True,\n",
    "            mode: EarlyStoppingMode | None = None,\n",
    "            split_multitask_scores: bool = False,\n",
    "    ):\n",
    "        \"\"\"Initialize the evaluation method class.\n",
    "\n",
    "        Args:\n",
    "            scoring: str | Callable[[Iterable, Iterable], float],\n",
    "            monitor (AssessorMonitor): monitor to track the evaluation\n",
    "            use_proba (bool): use probabilities for classification models\n",
    "            mode (EarlyStoppingMode): early stopping mode for fitting\n",
    "            split_multitask_scores (bool): whether to split the scores per task for multitask models\n",
    "        \"\"\"\n",
    "        self.monitor = monitor\n",
    "        self.useProba = use_proba\n",
    "        self.mode = mode\n",
    "        self.scoreFunc = (\n",
    "            SklearnMetrics(scoring) if isinstance(scoring, str) else scoring\n",
    "        )\n",
    "        self.splitMultitaskScores = split_multitask_scores\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(\n",
    "            self,\n",
    "            model: QSPRModel,\n",
    "            ds: QSPRDataset,\n",
    "            save: bool = True,\n",
    "            parameters: dict | None = None,\n",
    "            monitor: AssessorMonitor | None = None,\n",
    "            **kwargs,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Evaluate the model.\n",
    "\n",
    "        Args:\n",
    "            model (QSPRModel): model to evaluate\n",
    "            ds (QSPRDataset): dataset to evaluate on\n",
    "            save (bool): save predictions to file\n",
    "            parameters (dict): parameters to use for the evaluation\n",
    "            monitor (AssessorMonitor): monitor to track the evaluation, overrides\n",
    "                                       the monitor set in the constructor\n",
    "            kwargs: additional arguments for fit function of the model\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: scores for the model. If splitMultitaskScores is True, each\n",
    "            column represents a task and each row a fold. Otherwise, a 1D array is\n",
    "            returned with the scores for each fold.\n",
    "        \"\"\"\n",
    "\n",
    "    def predictionsToDataFrame(\n",
    "            self,\n",
    "            model: QSPRModel,\n",
    "            y: np.array,\n",
    "            predictions: np.ndarray | list[np.ndarray],\n",
    "            index: pd.Series,\n",
    "            extra_columns: dict[str, np.ndarray] | None = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Create a dataframe with true values and predictions.\n",
    "\n",
    "        Args:\n",
    "            model (QSPRModel): model to evaluate\n",
    "            y (np.array): target values\n",
    "            predictions (np.ndarray | list[np.ndarray]): predictions\n",
    "            index (pd.Series): index of the data set\n",
    "            extra_columns (dict[str, np.ndarray]): extra columns to add to the output\n",
    "        \"\"\"\n",
    "        # Create dataframe with true values\n",
    "        df_out = pd.DataFrame(\n",
    "            y.values, columns=y.add_suffix(\"_Label\").columns, index=index\n",
    "        )\n",
    "        # Add predictions to dataframe\n",
    "        for idx, prop in enumerate(model.targetProperties):\n",
    "            if prop.task.isClassification() and self.useProba:\n",
    "                # convert one-hot encoded predictions to class labels\n",
    "                # and add to train and test\n",
    "                df_out[f\"{prop.name}_Prediction\"] = np.argmax(predictions[idx], axis=1)\n",
    "                # add probability columns to train and test set\n",
    "                df_out = pd.concat(\n",
    "                    [\n",
    "                        df_out,\n",
    "                        pd.DataFrame(predictions[idx], index=index).add_prefix(\n",
    "                            f\"{prop.name}_ProbabilityClass_\"\n",
    "                        ),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "            else:\n",
    "                df_out[f\"{prop.name}_Prediction\"] = predictions[:, idx]\n",
    "        # Add extra columns to dataframe if given (such as fold indexes)\n",
    "        if extra_columns is not None:\n",
    "            for col_name, col_values in extra_columns.items():\n",
    "                df_out[col_name] = col_values\n",
    "        return df_out\n",
    "\n",
    "class TestSetAssessor(ModelAssessor):\n",
    "    \"\"\"Assess a model on a test set.\n",
    "\n",
    "    Attributes:+\n",
    "        useProba (bool): use predictProba instead of predict for classification\n",
    "        monitor (AssessorMonitor): monitor to use for assessment, if None, a BaseMonitor\n",
    "            is used\n",
    "        mode (EarlyStoppingMode): mode to use for early stopping\n",
    "        round (int): number of decimal places to round predictions to (default: 3)\n",
    "        splitMultitaskScores (bool): whether to split the scores per task for multitask models\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            scoring: str | Callable[[Iterable, Iterable], float],\n",
    "            monitor: AssessorMonitor | None = None,\n",
    "            use_proba: bool = True,\n",
    "            mode: EarlyStoppingMode | None = None,\n",
    "            round: int = 5,\n",
    "            split_multitask_scores: bool = False,\n",
    "    ):\n",
    "        super().__init__(scoring, monitor, use_proba, mode, split_multitask_scores)\n",
    "        if monitor is None:\n",
    "            self.monitor = BaseMonitor()\n",
    "        self.round = round\n",
    "\n",
    "    def __call__(\n",
    "            self,\n",
    "            model: QSPRModel,\n",
    "            ds: QSPRDataset,\n",
    "            save: bool = True,\n",
    "            parameters: dict | None = None,\n",
    "            monitor: AssessorMonitor | None = None,\n",
    "            **kwargs,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Make predictions for independent test set.\n",
    "\n",
    "        Arguments:\n",
    "            model (QSPRModel): model to assess\n",
    "            ds (QSPRDataset): dataset to assess on\n",
    "            scoring (str | Callable): scoring function to use\n",
    "            save (bool): whether to save predictions to file\n",
    "            parameters (dict): optional model parameters to use in assessment\n",
    "            use_proba (bool): use predictProba instead of predict for classification\n",
    "            monitor (AssessorMonitor): optional, overrides monitor set in constructor\n",
    "            **kwargs: additional keyword arguments for the fit function\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: scores for the test set. If splitMultitaskScores is True, each\n",
    "            column represents a task. Otherwise, a 1D array is returned with the score\n",
    "            for the test set.\n",
    "        \"\"\"\n",
    "        model.initFromDataset(ds)\n",
    "        monitor = monitor or self.monitor\n",
    "        evalparams = model.parameters if parameters is None else parameters\n",
    "        X, X_ind = ds.getFeatures()\n",
    "        y, y_ind = ds.getTargetPropertiesValues()\n",
    "        monitor.onAssessmentStart(model, ds, self.__class__.__name__)\n",
    "        monitor.onFoldStart(fold=0, X_train=X, y_train=y, X_test=X_ind, y_test=y_ind)\n",
    "        # fit model\n",
    "        ind_estimator = model.loadEstimator(evalparams)\n",
    "        ind_estimator = model.fit(\n",
    "            X, y, ind_estimator, self.mode, monitor=monitor, **kwargs\n",
    "        )\n",
    "        # predict values for independent test set\n",
    "        if model.task.isRegression() or not self.useProba:\n",
    "            predictions = model.predict(X_ind, ind_estimator)\n",
    "        else:\n",
    "            predictions = model.predictProba(X_ind, ind_estimator)\n",
    "        # score\n",
    "        try:\n",
    "            if model.isMultiTask and self.splitMultitaskScores:\n",
    "                scores_tasks = []\n",
    "                for idx, prop in enumerate(model.targetProperties):\n",
    "                    if self.useProba and prop.task.isClassification():\n",
    "                        prop_predictions = [predictions[idx]]\n",
    "                        scores_tasks.append(\n",
    "                            self.scoreFunc(y_ind.iloc[:, idx], prop_predictions)\n",
    "                        )\n",
    "                    else:\n",
    "                        scores_tasks.append(\n",
    "                            self.scoreFunc(y_ind.iloc[:, idx], predictions[:, idx])\n",
    "                        )\n",
    "                score = scores_tasks\n",
    "            else:\n",
    "                score = [self.scoreFunc(y_ind, predictions)]\n",
    "            predictions_df = self.predictionsToDataFrame(\n",
    "                model, y_ind, predictions, y_ind.index\n",
    "            )\n",
    "            monitor.onFoldEnd(ind_estimator, predictions_df)\n",
    "            # predict values for independent test set and save results\n",
    "            if save:\n",
    "                predictions_df.round(self.round).to_csv(\n",
    "                    f\"{model.outPrefix}.ind.tsv\", sep=\"\\t\"\n",
    "                )\n",
    "            monitor.onAssessmentEnd(predictions_df)\n",
    "            return np.array(score)\n",
    "        except:\n",
    "            print(\"Error is caused by either ... or by ...\")\n",
    "            print(prop)\n",
    "            print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total size = 13,860\n",
      "Fitting scaler\n",
      "Number of parameters = 356,706\n",
      "Moving trained model to cuda\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 1.0747e+00, PNorm = 34.0946, GNorm = 2.5035, lr_0 = 1.1787e-04\n",
      "Loss = 1.0146e+00, PNorm = 34.0948, GNorm = 2.8326, lr_0 = 1.3412e-04\n",
      "Loss = 9.4923e-01, PNorm = 34.0956, GNorm = 3.9701, lr_0 = 1.5036e-04\n",
      "Loss = 1.0028e+00, PNorm = 34.0974, GNorm = 3.4168, lr_0 = 1.6661e-04\n",
      "Loss = 9.3447e-01, PNorm = 34.1008, GNorm = 2.3995, lr_0 = 1.8285e-04\n",
      "Loss = 1.0220e+00, PNorm = 34.1052, GNorm = 2.1576, lr_0 = 1.9910e-04\n",
      "Loss = 9.3754e-01, PNorm = 34.1109, GNorm = 1.1340, lr_0 = 2.1534e-04\n",
      "Loss = 1.0059e+00, PNorm = 34.1172, GNorm = 6.4548, lr_0 = 2.3159e-04\n",
      "Loss = 8.8825e-01, PNorm = 34.1249, GNorm = 2.4476, lr_0 = 2.4783e-04\n",
      "Loss = 9.2004e-01, PNorm = 34.1352, GNorm = 1.2653, lr_0 = 2.6408e-04\n",
      "Loss = 8.7928e-01, PNorm = 34.1473, GNorm = 1.1705, lr_0 = 2.8032e-04\n",
      "Loss = 9.3702e-01, PNorm = 34.1603, GNorm = 2.7534, lr_0 = 2.9657e-04\n",
      "Loss = 8.9340e-01, PNorm = 34.1760, GNorm = 1.8875, lr_0 = 3.1282e-04\n",
      "Loss = 9.6562e-01, PNorm = 34.1903, GNorm = 9.1078, lr_0 = 3.2906e-04\n",
      "Loss = 1.0252e+00, PNorm = 34.2049, GNorm = 3.5727, lr_0 = 3.4531e-04\n",
      "Loss = 9.8084e-01, PNorm = 34.2216, GNorm = 3.1013, lr_0 = 3.6155e-04\n",
      "Loss = 9.6969e-01, PNorm = 34.2416, GNorm = 1.8510, lr_0 = 3.7780e-04\n",
      "Loss = 9.4402e-01, PNorm = 34.2640, GNorm = 2.1896, lr_0 = 3.9404e-04\n",
      "Loss = 9.1085e-01, PNorm = 34.2850, GNorm = 1.3129, lr_0 = 4.1029e-04\n",
      "Loss = 8.5977e-01, PNorm = 34.3124, GNorm = 1.6455, lr_0 = 4.2653e-04\n",
      "Loss = 7.8173e-01, PNorm = 34.3375, GNorm = 1.7464, lr_0 = 4.4278e-04\n",
      "Loss = 7.9323e-01, PNorm = 34.3658, GNorm = 2.4002, lr_0 = 4.5903e-04\n",
      "Loss = 8.1803e-01, PNorm = 34.3886, GNorm = 1.8902, lr_0 = 4.7527e-04\n",
      "Loss = 8.5296e-01, PNorm = 34.4123, GNorm = 2.3413, lr_0 = 4.9152e-04\n",
      "Loss = 8.0919e-01, PNorm = 34.4448, GNorm = 1.5841, lr_0 = 5.0776e-04\n",
      "Loss = 8.8636e-01, PNorm = 34.4810, GNorm = 3.1887, lr_0 = 5.2401e-04\n",
      "Loss = 7.1312e-01, PNorm = 34.5105, GNorm = 1.3156, lr_0 = 5.4025e-04\n",
      "  5%|â–Œ         | 1/20 [00:17<05:28, 17.30s/it]Epoch 1\n",
      "Loss = 8.0876e-01, PNorm = 34.5462, GNorm = 1.9608, lr_0 = 5.5812e-04\n",
      "Loss = 9.2176e-01, PNorm = 34.5827, GNorm = 1.8636, lr_0 = 5.7437e-04\n",
      "Loss = 8.5748e-01, PNorm = 34.6260, GNorm = 2.1118, lr_0 = 5.9061e-04\n",
      "Loss = 7.9760e-01, PNorm = 34.6703, GNorm = 0.8941, lr_0 = 6.0686e-04\n",
      "Loss = 8.1905e-01, PNorm = 34.7066, GNorm = 1.2368, lr_0 = 6.2310e-04\n",
      "Loss = 7.7652e-01, PNorm = 34.7453, GNorm = 1.3934, lr_0 = 6.3935e-04\n",
      "Loss = 7.5353e-01, PNorm = 34.7866, GNorm = 1.6522, lr_0 = 6.5560e-04\n",
      "Loss = 9.0923e-01, PNorm = 34.8348, GNorm = 4.2424, lr_0 = 6.7184e-04\n",
      "Loss = 7.8420e-01, PNorm = 34.8861, GNorm = 2.2020, lr_0 = 6.8809e-04\n",
      "Loss = 7.5354e-01, PNorm = 34.9352, GNorm = 1.9176, lr_0 = 7.0433e-04\n",
      "Loss = 6.7931e-01, PNorm = 34.9751, GNorm = 2.5618, lr_0 = 7.2058e-04\n",
      "Loss = 6.8721e-01, PNorm = 35.0165, GNorm = 2.7878, lr_0 = 7.3682e-04\n",
      "Loss = 7.8539e-01, PNorm = 35.0665, GNorm = 0.9026, lr_0 = 7.5307e-04\n",
      "Loss = 7.8250e-01, PNorm = 35.1185, GNorm = 5.6500, lr_0 = 7.6931e-04\n",
      "Loss = 7.9535e-01, PNorm = 35.1502, GNorm = 2.1236, lr_0 = 7.8556e-04\n",
      "Loss = 7.6723e-01, PNorm = 35.1903, GNorm = 1.2167, lr_0 = 8.0181e-04\n",
      "Loss = 8.5366e-01, PNorm = 35.2537, GNorm = 0.8945, lr_0 = 8.1805e-04\n",
      "Loss = 7.4746e-01, PNorm = 35.3046, GNorm = 0.5570, lr_0 = 8.3430e-04\n",
      "Loss = 7.2706e-01, PNorm = 35.3507, GNorm = 2.6109, lr_0 = 8.5054e-04\n",
      "Loss = 7.6630e-01, PNorm = 35.3927, GNorm = 2.2051, lr_0 = 8.6679e-04\n",
      "Loss = 8.2652e-01, PNorm = 35.4555, GNorm = 5.7013, lr_0 = 8.8303e-04\n",
      "Loss = 7.9895e-01, PNorm = 35.5068, GNorm = 1.0554, lr_0 = 8.9928e-04\n",
      "Loss = 7.0686e-01, PNorm = 35.5609, GNorm = 2.3168, lr_0 = 9.1552e-04\n",
      "Loss = 7.7063e-01, PNorm = 35.6203, GNorm = 3.1871, lr_0 = 9.3177e-04\n",
      "Loss = 7.7363e-01, PNorm = 35.6756, GNorm = 1.4859, lr_0 = 9.4801e-04\n",
      "Loss = 7.8291e-01, PNorm = 35.7482, GNorm = 0.6030, lr_0 = 9.6426e-04\n",
      "Loss = 7.0027e-01, PNorm = 35.8157, GNorm = 2.3104, lr_0 = 9.8051e-04\n",
      "Loss = 6.3464e-01, PNorm = 35.8789, GNorm = 1.2925, lr_0 = 9.9675e-04\n",
      " 10%|â–ˆ         | 2/20 [00:34<05:09, 17.19s/it]Epoch 2\n",
      "Loss = 8.8796e-01, PNorm = 35.9399, GNorm = 2.1598, lr_0 = 9.7537e-04\n",
      "Loss = 6.7393e-01, PNorm = 35.9925, GNorm = 1.6779, lr_0 = 9.4872e-04\n",
      "Loss = 7.0272e-01, PNorm = 36.0518, GNorm = 1.4047, lr_0 = 9.2279e-04\n",
      "Loss = 7.3484e-01, PNorm = 36.1040, GNorm = 1.8705, lr_0 = 8.9757e-04\n",
      "Loss = 6.7292e-01, PNorm = 36.1494, GNorm = 1.1330, lr_0 = 8.7304e-04\n",
      "Loss = 7.1033e-01, PNorm = 36.1954, GNorm = 1.6991, lr_0 = 8.4918e-04\n",
      "Loss = 7.2173e-01, PNorm = 36.2437, GNorm = 1.4273, lr_0 = 8.2598e-04\n",
      "Loss = 6.4918e-01, PNorm = 36.2850, GNorm = 1.0463, lr_0 = 8.0340e-04\n",
      "Loss = 6.7815e-01, PNorm = 36.3290, GNorm = 0.7402, lr_0 = 7.8145e-04\n",
      "Loss = 6.7435e-01, PNorm = 36.3642, GNorm = 0.5346, lr_0 = 7.6009e-04\n",
      "Loss = 7.1842e-01, PNorm = 36.4118, GNorm = 1.2536, lr_0 = 7.3932e-04\n",
      "Loss = 6.2288e-01, PNorm = 36.4577, GNorm = 1.6210, lr_0 = 7.1912e-04\n",
      "Loss = 6.6644e-01, PNorm = 36.4862, GNorm = 1.3052, lr_0 = 6.9946e-04\n",
      "Loss = 6.8295e-01, PNorm = 36.5210, GNorm = 2.2439, lr_0 = 6.8035e-04\n",
      "Loss = 6.2818e-01, PNorm = 36.5594, GNorm = 1.6274, lr_0 = 6.6176e-04\n",
      "Loss = 5.8887e-01, PNorm = 36.5942, GNorm = 1.8657, lr_0 = 6.4367e-04\n",
      "Loss = 5.3126e-01, PNorm = 36.6322, GNorm = 1.3156, lr_0 = 6.2608e-04\n",
      "Loss = 6.5684e-01, PNorm = 36.6656, GNorm = 1.6852, lr_0 = 6.0897e-04\n",
      "Loss = 6.0283e-01, PNorm = 36.6982, GNorm = 1.1877, lr_0 = 5.9233e-04\n",
      "Loss = 6.5295e-01, PNorm = 36.7350, GNorm = 0.7806, lr_0 = 5.7614e-04\n",
      "Loss = 6.0319e-01, PNorm = 36.7636, GNorm = 1.3932, lr_0 = 5.6040e-04\n",
      "Loss = 6.1523e-01, PNorm = 36.7886, GNorm = 1.1322, lr_0 = 5.4508e-04\n",
      "Loss = 6.0097e-01, PNorm = 36.8176, GNorm = 0.7300, lr_0 = 5.3019e-04\n",
      "Loss = 5.8343e-01, PNorm = 36.8443, GNorm = 0.9845, lr_0 = 5.1570e-04\n",
      "Loss = 6.9741e-01, PNorm = 36.8700, GNorm = 2.0189, lr_0 = 5.0160e-04\n",
      "Loss = 7.1085e-01, PNorm = 36.9039, GNorm = 2.3720, lr_0 = 4.8790e-04\n",
      "Loss = 6.4005e-01, PNorm = 36.9309, GNorm = 1.1096, lr_0 = 4.7456e-04\n",
      "Loss = 6.5025e-01, PNorm = 36.9489, GNorm = 1.3889, lr_0 = 4.6159e-04\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:50<04:44, 16.71s/it]Epoch 3\n",
      "Loss = 5.9616e-01, PNorm = 36.9681, GNorm = 1.6027, lr_0 = 4.4774e-04\n",
      "Loss = 5.6362e-01, PNorm = 36.9897, GNorm = 1.7804, lr_0 = 4.3550e-04\n",
      "Loss = 6.2033e-01, PNorm = 37.0166, GNorm = 2.1161, lr_0 = 4.2360e-04\n",
      "Loss = 7.1197e-01, PNorm = 37.0421, GNorm = 1.0621, lr_0 = 4.1202e-04\n",
      "Loss = 5.9351e-01, PNorm = 37.0657, GNorm = 2.4708, lr_0 = 4.0076e-04\n",
      "Loss = 5.2676e-01, PNorm = 37.0891, GNorm = 1.8038, lr_0 = 3.8981e-04\n",
      "Loss = 5.9188e-01, PNorm = 37.1078, GNorm = 0.8863, lr_0 = 3.7916e-04\n",
      "Loss = 5.7457e-01, PNorm = 37.1247, GNorm = 0.9405, lr_0 = 3.6880e-04\n",
      "Loss = 6.2932e-01, PNorm = 37.1409, GNorm = 2.8038, lr_0 = 3.5872e-04\n",
      "Loss = 6.2929e-01, PNorm = 37.1562, GNorm = 1.6974, lr_0 = 3.4891e-04\n",
      "Loss = 5.4052e-01, PNorm = 37.1764, GNorm = 1.7470, lr_0 = 3.3938e-04\n",
      "Loss = 5.9843e-01, PNorm = 37.1924, GNorm = 2.4861, lr_0 = 3.3011e-04\n",
      "Loss = 5.7684e-01, PNorm = 37.2071, GNorm = 1.8577, lr_0 = 3.2108e-04\n",
      "Loss = 5.9527e-01, PNorm = 37.2250, GNorm = 1.1669, lr_0 = 3.1231e-04\n",
      "Loss = 5.8202e-01, PNorm = 37.2423, GNorm = 0.9992, lr_0 = 3.0377e-04\n",
      "Loss = 5.6340e-01, PNorm = 37.2550, GNorm = 1.8732, lr_0 = 2.9547e-04\n",
      "Loss = 6.3048e-01, PNorm = 37.2693, GNorm = 1.2638, lr_0 = 2.8740e-04\n",
      "Loss = 5.8145e-01, PNorm = 37.2860, GNorm = 1.9738, lr_0 = 2.7954e-04\n",
      "Loss = 5.6666e-01, PNorm = 37.3029, GNorm = 1.7337, lr_0 = 2.7190e-04\n",
      "Loss = 4.8514e-01, PNorm = 37.3170, GNorm = 1.6250, lr_0 = 2.6447e-04\n",
      "Loss = 4.6812e-01, PNorm = 37.3300, GNorm = 1.1264, lr_0 = 2.5725e-04\n",
      "Loss = 5.5258e-01, PNorm = 37.3431, GNorm = 1.3078, lr_0 = 2.5022e-04\n",
      "Loss = 5.5739e-01, PNorm = 37.3552, GNorm = 2.6555, lr_0 = 2.4338e-04\n",
      "Loss = 6.1052e-01, PNorm = 37.3693, GNorm = 1.3377, lr_0 = 2.3673e-04\n",
      "Loss = 5.9988e-01, PNorm = 37.3811, GNorm = 1.2468, lr_0 = 2.3026e-04\n",
      "Loss = 5.9872e-01, PNorm = 37.3920, GNorm = 1.1765, lr_0 = 2.2397e-04\n",
      "Loss = 5.8368e-01, PNorm = 37.4032, GNorm = 1.1900, lr_0 = 2.1784e-04\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [01:08<04:32, 17.05s/it]Epoch 4\n",
      "Loss = 6.3806e-01, PNorm = 37.4181, GNorm = 3.2253, lr_0 = 2.1130e-04\n",
      "Loss = 4.1708e-01, PNorm = 37.4306, GNorm = 2.2882, lr_0 = 2.0553e-04\n",
      "Loss = 5.7537e-01, PNorm = 37.4414, GNorm = 1.7248, lr_0 = 1.9991e-04\n",
      "Loss = 4.9313e-01, PNorm = 37.4519, GNorm = 1.0916, lr_0 = 1.9445e-04\n",
      "Loss = 5.8585e-01, PNorm = 37.4647, GNorm = 1.1214, lr_0 = 1.8914e-04\n",
      "Loss = 5.1111e-01, PNorm = 37.4721, GNorm = 2.1212, lr_0 = 1.8397e-04\n",
      "Loss = 5.4145e-01, PNorm = 37.4818, GNorm = 1.1466, lr_0 = 1.7894e-04\n",
      "Loss = 5.5542e-01, PNorm = 37.4939, GNorm = 1.7591, lr_0 = 1.7405e-04\n",
      "Loss = 5.0475e-01, PNorm = 37.5036, GNorm = 1.3955, lr_0 = 1.6929e-04\n",
      "Loss = 5.8824e-01, PNorm = 37.5118, GNorm = 1.4590, lr_0 = 1.6467e-04\n",
      "Loss = 5.7002e-01, PNorm = 37.5184, GNorm = 1.3410, lr_0 = 1.6017e-04\n",
      "Loss = 5.1244e-01, PNorm = 37.5259, GNorm = 2.3103, lr_0 = 1.5579e-04\n",
      "Loss = 5.4522e-01, PNorm = 37.5329, GNorm = 1.4722, lr_0 = 1.5153e-04\n",
      "Loss = 5.9281e-01, PNorm = 37.5419, GNorm = 1.4599, lr_0 = 1.4739e-04\n",
      "Loss = 5.4411e-01, PNorm = 37.5485, GNorm = 1.7568, lr_0 = 1.4336e-04\n",
      "Loss = 5.2326e-01, PNorm = 37.5551, GNorm = 0.9924, lr_0 = 1.3945e-04\n",
      "Loss = 5.1613e-01, PNorm = 37.5616, GNorm = 1.9518, lr_0 = 1.3563e-04\n",
      "Loss = 5.1767e-01, PNorm = 37.5674, GNorm = 1.1936, lr_0 = 1.3193e-04\n",
      "Loss = 5.5008e-01, PNorm = 37.5737, GNorm = 1.3610, lr_0 = 1.2832e-04\n",
      "Loss = 5.5282e-01, PNorm = 37.5785, GNorm = 1.4401, lr_0 = 1.2482e-04\n",
      "Loss = 5.0639e-01, PNorm = 37.5840, GNorm = 1.4690, lr_0 = 1.2140e-04\n",
      "Loss = 5.4921e-01, PNorm = 37.5914, GNorm = 1.6986, lr_0 = 1.1809e-04\n",
      "Loss = 4.7111e-01, PNorm = 37.5970, GNorm = 1.4031, lr_0 = 1.1486e-04\n",
      "Loss = 5.1158e-01, PNorm = 37.6006, GNorm = 2.3970, lr_0 = 1.1172e-04\n",
      "Loss = 5.5723e-01, PNorm = 37.6051, GNorm = 2.1676, lr_0 = 1.0867e-04\n",
      "Loss = 5.4937e-01, PNorm = 37.6090, GNorm = 2.0849, lr_0 = 1.0570e-04\n",
      "Loss = 5.6854e-01, PNorm = 37.6140, GNorm = 3.3369, lr_0 = 1.0281e-04\n",
      "Loss = 5.2927e-01, PNorm = 37.6200, GNorm = 1.6841, lr_0 = 1.0000e-04\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [01:25<04:17, 17.19s/it]Epoch 5\n",
      "Loss = 4.6892e-01, PNorm = 37.6243, GNorm = 2.0557, lr_0 = 1.0000e-04\n",
      "Loss = 5.5355e-01, PNorm = 37.6292, GNorm = 1.6554, lr_0 = 1.0000e-04\n",
      "Loss = 5.7206e-01, PNorm = 37.6345, GNorm = 3.4749, lr_0 = 1.0000e-04\n",
      "Loss = 5.4266e-01, PNorm = 37.6398, GNorm = 1.6434, lr_0 = 1.0000e-04\n",
      "Loss = 5.5539e-01, PNorm = 37.6456, GNorm = 1.5232, lr_0 = 1.0000e-04\n",
      "Loss = 4.9569e-01, PNorm = 37.6504, GNorm = 1.6216, lr_0 = 1.0000e-04\n",
      "Loss = 4.8259e-01, PNorm = 37.6540, GNorm = 1.5564, lr_0 = 1.0000e-04\n",
      "Loss = 5.2410e-01, PNorm = 37.6572, GNorm = 2.0806, lr_0 = 1.0000e-04\n",
      "Loss = 5.6652e-01, PNorm = 37.6604, GNorm = 1.1797, lr_0 = 1.0000e-04\n",
      "Loss = 5.1838e-01, PNorm = 37.6650, GNorm = 1.9202, lr_0 = 1.0000e-04\n",
      "Loss = 5.5471e-01, PNorm = 37.6715, GNorm = 1.6455, lr_0 = 1.0000e-04\n",
      "Loss = 4.9207e-01, PNorm = 37.6766, GNorm = 1.3245, lr_0 = 1.0000e-04\n",
      "Loss = 4.5319e-01, PNorm = 37.6810, GNorm = 1.1527, lr_0 = 1.0000e-04\n",
      "Loss = 5.2212e-01, PNorm = 37.6872, GNorm = 1.2713, lr_0 = 1.0000e-04\n",
      "Loss = 4.8881e-01, PNorm = 37.6919, GNorm = 3.6197, lr_0 = 1.0000e-04\n",
      "Loss = 5.0438e-01, PNorm = 37.6960, GNorm = 1.5811, lr_0 = 1.0000e-04\n",
      "Loss = 5.1868e-01, PNorm = 37.7005, GNorm = 1.0925, lr_0 = 1.0000e-04\n",
      "Loss = 4.9194e-01, PNorm = 37.7052, GNorm = 1.5511, lr_0 = 1.0000e-04\n",
      "Loss = 5.2809e-01, PNorm = 37.7095, GNorm = 1.8259, lr_0 = 1.0000e-04\n",
      "Loss = 5.4345e-01, PNorm = 37.7125, GNorm = 1.6407, lr_0 = 1.0000e-04\n",
      "Loss = 5.1866e-01, PNorm = 37.7168, GNorm = 1.4622, lr_0 = 1.0000e-04\n",
      "Loss = 5.3251e-01, PNorm = 37.7229, GNorm = 1.3842, lr_0 = 1.0000e-04\n",
      "Loss = 5.5582e-01, PNorm = 37.7288, GNorm = 1.1669, lr_0 = 1.0000e-04\n",
      "Loss = 4.9674e-01, PNorm = 37.7344, GNorm = 1.8418, lr_0 = 1.0000e-04\n",
      "Loss = 4.8189e-01, PNorm = 37.7394, GNorm = 1.3514, lr_0 = 1.0000e-04\n",
      "Loss = 5.0842e-01, PNorm = 37.7443, GNorm = 2.3657, lr_0 = 1.0000e-04\n",
      "Loss = 4.9353e-01, PNorm = 37.7472, GNorm = 1.2964, lr_0 = 1.0000e-04\n",
      "Loss = 5.0900e-01, PNorm = 37.7506, GNorm = 1.9385, lr_0 = 1.0000e-04\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [01:43<04:03, 17.37s/it]Epoch 6\n",
      "Loss = 4.9500e-01, PNorm = 37.7553, GNorm = 0.9831, lr_0 = 1.0000e-04\n",
      "Loss = 5.2819e-01, PNorm = 37.7594, GNorm = 1.2638, lr_0 = 1.0000e-04\n",
      "Loss = 5.1546e-01, PNorm = 37.7639, GNorm = 1.2623, lr_0 = 1.0000e-04\n",
      "Loss = 4.8049e-01, PNorm = 37.7686, GNorm = 1.3346, lr_0 = 1.0000e-04\n",
      "Loss = 4.7337e-01, PNorm = 37.7731, GNorm = 2.9451, lr_0 = 1.0000e-04\n",
      "Loss = 5.0609e-01, PNorm = 37.7776, GNorm = 2.1219, lr_0 = 1.0000e-04\n",
      "Loss = 5.1735e-01, PNorm = 37.7825, GNorm = 2.1674, lr_0 = 1.0000e-04\n",
      "Loss = 4.8246e-01, PNorm = 37.7872, GNorm = 0.9403, lr_0 = 1.0000e-04\n",
      "Loss = 4.4017e-01, PNorm = 37.7910, GNorm = 2.5506, lr_0 = 1.0000e-04\n",
      "Loss = 5.5704e-01, PNorm = 37.7960, GNorm = 2.4324, lr_0 = 1.0000e-04\n",
      "Loss = 5.4968e-01, PNorm = 37.8010, GNorm = 1.1831, lr_0 = 1.0000e-04\n",
      "Loss = 4.1982e-01, PNorm = 37.8063, GNorm = 1.8117, lr_0 = 1.0000e-04\n",
      "Loss = 5.4577e-01, PNorm = 37.8110, GNorm = 1.1508, lr_0 = 1.0000e-04\n",
      "Loss = 4.9603e-01, PNorm = 37.8165, GNorm = 1.8917, lr_0 = 1.0000e-04\n",
      "Loss = 6.0596e-01, PNorm = 37.8212, GNorm = 2.0588, lr_0 = 1.0000e-04\n",
      "Loss = 4.8907e-01, PNorm = 37.8259, GNorm = 1.3709, lr_0 = 1.0000e-04\n",
      "Loss = 4.9763e-01, PNorm = 37.8300, GNorm = 1.2973, lr_0 = 1.0000e-04\n",
      "Loss = 5.4599e-01, PNorm = 37.8346, GNorm = 2.3325, lr_0 = 1.0000e-04\n",
      "Loss = 5.0053e-01, PNorm = 37.8392, GNorm = 1.3383, lr_0 = 1.0000e-04\n",
      "Loss = 5.1019e-01, PNorm = 37.8428, GNorm = 1.1592, lr_0 = 1.0000e-04\n",
      "Loss = 5.4131e-01, PNorm = 37.8463, GNorm = 1.4778, lr_0 = 1.0000e-04\n",
      "Loss = 4.7796e-01, PNorm = 37.8515, GNorm = 1.6195, lr_0 = 1.0000e-04\n",
      "Loss = 4.4173e-01, PNorm = 37.8563, GNorm = 2.4652, lr_0 = 1.0000e-04\n",
      "Loss = 4.9631e-01, PNorm = 37.8620, GNorm = 1.2643, lr_0 = 1.0000e-04\n",
      "Loss = 4.9916e-01, PNorm = 37.8665, GNorm = 2.0435, lr_0 = 1.0000e-04\n",
      "Loss = 4.8386e-01, PNorm = 37.8713, GNorm = 1.6990, lr_0 = 1.0000e-04\n",
      "Loss = 5.1475e-01, PNorm = 37.8751, GNorm = 1.7090, lr_0 = 1.0000e-04\n",
      "Loss = 5.0459e-01, PNorm = 37.8796, GNorm = 2.8276, lr_0 = 1.0000e-04\n",
      "Loss = 5.6291e-01, PNorm = 37.8799, GNorm = 6.4315, lr_0 = 1.0000e-04\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [02:00<03:43, 17.18s/it]Epoch 7\n",
      "Loss = 5.3357e-01, PNorm = 37.8838, GNorm = 0.9981, lr_0 = 1.0000e-04\n",
      "Loss = 5.0461e-01, PNorm = 37.8903, GNorm = 2.2744, lr_0 = 1.0000e-04\n",
      "Loss = 4.8381e-01, PNorm = 37.8955, GNorm = 1.8201, lr_0 = 1.0000e-04\n",
      "Loss = 4.9484e-01, PNorm = 37.9015, GNorm = 1.6369, lr_0 = 1.0000e-04\n",
      "Loss = 4.8250e-01, PNorm = 37.9065, GNorm = 2.2900, lr_0 = 1.0000e-04\n",
      "Loss = 5.2181e-01, PNorm = 37.9114, GNorm = 2.2647, lr_0 = 1.0000e-04\n",
      "Loss = 4.9141e-01, PNorm = 37.9150, GNorm = 1.6636, lr_0 = 1.0000e-04\n",
      "Loss = 5.2257e-01, PNorm = 37.9186, GNorm = 1.5665, lr_0 = 1.0000e-04\n",
      "Loss = 4.8186e-01, PNorm = 37.9212, GNorm = 2.1729, lr_0 = 1.0000e-04\n",
      "Loss = 4.7409e-01, PNorm = 37.9256, GNorm = 1.7660, lr_0 = 1.0000e-04\n",
      "Loss = 5.6693e-01, PNorm = 37.9298, GNorm = 1.4603, lr_0 = 1.0000e-04\n",
      "Loss = 4.5930e-01, PNorm = 37.9340, GNorm = 1.5497, lr_0 = 1.0000e-04\n",
      "Loss = 5.3103e-01, PNorm = 37.9379, GNorm = 2.1196, lr_0 = 1.0000e-04\n",
      "Loss = 4.8891e-01, PNorm = 37.9423, GNorm = 2.5112, lr_0 = 1.0000e-04\n",
      "Loss = 4.6178e-01, PNorm = 37.9472, GNorm = 1.0966, lr_0 = 1.0000e-04\n",
      "Loss = 5.4171e-01, PNorm = 37.9513, GNorm = 1.8067, lr_0 = 1.0000e-04\n",
      "Loss = 4.8530e-01, PNorm = 37.9551, GNorm = 1.7997, lr_0 = 1.0000e-04\n",
      "Loss = 4.7027e-01, PNorm = 37.9600, GNorm = 1.7688, lr_0 = 1.0000e-04\n",
      "Loss = 4.6223e-01, PNorm = 37.9646, GNorm = 2.5287, lr_0 = 1.0000e-04\n",
      "Loss = 5.0882e-01, PNorm = 37.9699, GNorm = 1.8468, lr_0 = 1.0000e-04\n",
      "Loss = 5.2505e-01, PNorm = 37.9744, GNorm = 1.4135, lr_0 = 1.0000e-04\n",
      "Loss = 4.7995e-01, PNorm = 37.9787, GNorm = 2.7089, lr_0 = 1.0000e-04\n",
      "Loss = 4.3369e-01, PNorm = 37.9828, GNorm = 1.6695, lr_0 = 1.0000e-04\n",
      "Loss = 4.4319e-01, PNorm = 37.9858, GNorm = 2.2014, lr_0 = 1.0000e-04\n",
      "Loss = 5.1851e-01, PNorm = 37.9889, GNorm = 1.8982, lr_0 = 1.0000e-04\n",
      "Loss = 4.9088e-01, PNorm = 37.9934, GNorm = 1.3895, lr_0 = 1.0000e-04\n",
      "Loss = 4.7869e-01, PNorm = 37.9987, GNorm = 1.2922, lr_0 = 1.0000e-04\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [02:17<03:26, 17.20s/it]Epoch 8\n",
      "Loss = 5.0577e-01, PNorm = 38.0052, GNorm = 1.6378, lr_0 = 1.0000e-04\n",
      "Loss = 4.8428e-01, PNorm = 38.0115, GNorm = 1.7268, lr_0 = 1.0000e-04\n",
      "Loss = 4.8389e-01, PNorm = 38.0165, GNorm = 2.1595, lr_0 = 1.0000e-04\n",
      "Loss = 4.9712e-01, PNorm = 38.0200, GNorm = 2.5500, lr_0 = 1.0000e-04\n",
      "Loss = 4.8174e-01, PNorm = 38.0253, GNorm = 1.8441, lr_0 = 1.0000e-04\n",
      "Loss = 5.0551e-01, PNorm = 38.0321, GNorm = 1.7690, lr_0 = 1.0000e-04\n",
      "Loss = 4.8343e-01, PNorm = 38.0372, GNorm = 1.8970, lr_0 = 1.0000e-04\n",
      "Loss = 4.6061e-01, PNorm = 38.0408, GNorm = 1.6043, lr_0 = 1.0000e-04\n",
      "Loss = 4.9438e-01, PNorm = 38.0439, GNorm = 1.5648, lr_0 = 1.0000e-04\n",
      "Loss = 4.3073e-01, PNorm = 38.0479, GNorm = 1.4948, lr_0 = 1.0000e-04\n",
      "Loss = 5.3742e-01, PNorm = 38.0510, GNorm = 2.5694, lr_0 = 1.0000e-04\n",
      "Loss = 4.3915e-01, PNorm = 38.0547, GNorm = 1.5085, lr_0 = 1.0000e-04\n",
      "Loss = 5.0752e-01, PNorm = 38.0582, GNorm = 1.2726, lr_0 = 1.0000e-04\n",
      "Loss = 4.8325e-01, PNorm = 38.0628, GNorm = 2.8703, lr_0 = 1.0000e-04\n",
      "Loss = 5.0232e-01, PNorm = 38.0672, GNorm = 2.4805, lr_0 = 1.0000e-04\n",
      "Loss = 4.2709e-01, PNorm = 38.0724, GNorm = 1.7005, lr_0 = 1.0000e-04\n",
      "Loss = 4.6029e-01, PNorm = 38.0779, GNorm = 1.0245, lr_0 = 1.0000e-04\n",
      "Loss = 4.9369e-01, PNorm = 38.0824, GNorm = 1.3674, lr_0 = 1.0000e-04\n",
      "Loss = 4.4118e-01, PNorm = 38.0871, GNorm = 1.2931, lr_0 = 1.0000e-04\n",
      "Loss = 5.2642e-01, PNorm = 38.0914, GNorm = 1.7367, lr_0 = 1.0000e-04\n",
      "Loss = 4.5627e-01, PNorm = 38.0945, GNorm = 1.7307, lr_0 = 1.0000e-04\n",
      "Loss = 5.2211e-01, PNorm = 38.0990, GNorm = 1.1267, lr_0 = 1.0000e-04\n",
      "Loss = 4.9078e-01, PNorm = 38.1044, GNorm = 1.5054, lr_0 = 1.0000e-04\n",
      "Loss = 4.4516e-01, PNorm = 38.1090, GNorm = 2.6023, lr_0 = 1.0000e-04\n",
      "Loss = 4.6661e-01, PNorm = 38.1130, GNorm = 4.0234, lr_0 = 1.0000e-04\n",
      "Loss = 5.0687e-01, PNorm = 38.1167, GNorm = 1.7778, lr_0 = 1.0000e-04\n",
      "Loss = 5.3511e-01, PNorm = 38.1207, GNorm = 3.0483, lr_0 = 1.0000e-04\n",
      "Loss = 5.0059e-01, PNorm = 38.1239, GNorm = 1.4838, lr_0 = 1.0000e-04\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [02:34<03:09, 17.21s/it]Epoch 9\n",
      "Loss = 4.4479e-01, PNorm = 38.1279, GNorm = 1.5516, lr_0 = 1.0000e-04\n",
      "Loss = 5.1923e-01, PNorm = 38.1334, GNorm = 2.5774, lr_0 = 1.0000e-04\n",
      "Loss = 4.5753e-01, PNorm = 38.1388, GNorm = 1.2318, lr_0 = 1.0000e-04\n",
      "Loss = 4.9806e-01, PNorm = 38.1441, GNorm = 1.7440, lr_0 = 1.0000e-04\n",
      "Loss = 4.9163e-01, PNorm = 38.1480, GNorm = 2.6786, lr_0 = 1.0000e-04\n",
      "Loss = 4.8810e-01, PNorm = 38.1517, GNorm = 2.9203, lr_0 = 1.0000e-04\n",
      "Loss = 5.1139e-01, PNorm = 38.1559, GNorm = 1.7513, lr_0 = 1.0000e-04\n",
      "Loss = 4.5199e-01, PNorm = 38.1599, GNorm = 1.1824, lr_0 = 1.0000e-04\n",
      "Loss = 4.7820e-01, PNorm = 38.1649, GNorm = 1.6134, lr_0 = 1.0000e-04\n",
      "Loss = 4.7331e-01, PNorm = 38.1685, GNorm = 1.8959, lr_0 = 1.0000e-04\n",
      "Loss = 4.4725e-01, PNorm = 38.1729, GNorm = 1.3753, lr_0 = 1.0000e-04\n",
      "Loss = 4.4472e-01, PNorm = 38.1763, GNorm = 1.6780, lr_0 = 1.0000e-04\n",
      "Loss = 4.6134e-01, PNorm = 38.1801, GNorm = 1.1948, lr_0 = 1.0000e-04\n",
      "Loss = 4.5221e-01, PNorm = 38.1845, GNorm = 2.9828, lr_0 = 1.0000e-04\n",
      "Loss = 4.4234e-01, PNorm = 38.1890, GNorm = 2.1561, lr_0 = 1.0000e-04\n",
      "Loss = 5.1087e-01, PNorm = 38.1929, GNorm = 2.4711, lr_0 = 1.0000e-04\n",
      "Loss = 5.0277e-01, PNorm = 38.1969, GNorm = 2.4672, lr_0 = 1.0000e-04\n",
      "Loss = 4.9193e-01, PNorm = 38.2004, GNorm = 1.7475, lr_0 = 1.0000e-04\n",
      "Loss = 4.9537e-01, PNorm = 38.2042, GNorm = 2.0984, lr_0 = 1.0000e-04\n",
      "Loss = 4.4343e-01, PNorm = 38.2078, GNorm = 1.7734, lr_0 = 1.0000e-04\n",
      "Loss = 4.7630e-01, PNorm = 38.2113, GNorm = 3.1765, lr_0 = 1.0000e-04\n",
      "Loss = 4.7818e-01, PNorm = 38.2165, GNorm = 2.3406, lr_0 = 1.0000e-04\n",
      "Loss = 4.3548e-01, PNorm = 38.2215, GNorm = 1.7141, lr_0 = 1.0000e-04\n",
      "Loss = 4.4047e-01, PNorm = 38.2264, GNorm = 1.7539, lr_0 = 1.0000e-04\n",
      "Loss = 4.8288e-01, PNorm = 38.2307, GNorm = 1.6982, lr_0 = 1.0000e-04\n",
      "Loss = 5.4160e-01, PNorm = 38.2358, GNorm = 2.3056, lr_0 = 1.0000e-04\n",
      "Loss = 4.6332e-01, PNorm = 38.2400, GNorm = 2.0066, lr_0 = 1.0000e-04\n",
      "Loss = 4.6666e-01, PNorm = 38.2450, GNorm = 1.7990, lr_0 = 1.0000e-04\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [02:51<02:52, 17.24s/it]Epoch 10\n",
      "Loss = 5.0396e-01, PNorm = 38.2496, GNorm = 3.1708, lr_0 = 1.0000e-04\n",
      "Loss = 4.6752e-01, PNorm = 38.2536, GNorm = 2.2083, lr_0 = 1.0000e-04\n",
      "Loss = 4.9649e-01, PNorm = 38.2585, GNorm = 1.7628, lr_0 = 1.0000e-04\n",
      "Loss = 4.3955e-01, PNorm = 38.2636, GNorm = 2.2631, lr_0 = 1.0000e-04\n",
      "Loss = 4.2390e-01, PNorm = 38.2674, GNorm = 1.1980, lr_0 = 1.0000e-04\n",
      "Loss = 4.7462e-01, PNorm = 38.2714, GNorm = 1.5250, lr_0 = 1.0000e-04\n",
      "Loss = 4.5528e-01, PNorm = 38.2765, GNorm = 1.7278, lr_0 = 1.0000e-04\n",
      "Loss = 4.7786e-01, PNorm = 38.2821, GNorm = 1.7764, lr_0 = 1.0000e-04\n",
      "Loss = 4.6861e-01, PNorm = 38.2868, GNorm = 4.2535, lr_0 = 1.0000e-04\n",
      "Loss = 4.4768e-01, PNorm = 38.2906, GNorm = 1.8037, lr_0 = 1.0000e-04\n",
      "Loss = 4.7688e-01, PNorm = 38.2941, GNorm = 1.9599, lr_0 = 1.0000e-04\n",
      "Loss = 4.5947e-01, PNorm = 38.2970, GNorm = 1.6040, lr_0 = 1.0000e-04\n",
      "Loss = 4.8883e-01, PNorm = 38.3002, GNorm = 2.8050, lr_0 = 1.0000e-04\n",
      "Loss = 4.4539e-01, PNorm = 38.3046, GNorm = 1.7664, lr_0 = 1.0000e-04\n",
      "Loss = 4.0577e-01, PNorm = 38.3086, GNorm = 1.2556, lr_0 = 1.0000e-04\n",
      "Loss = 4.7516e-01, PNorm = 38.3133, GNorm = 1.7996, lr_0 = 1.0000e-04\n",
      "Loss = 4.9954e-01, PNorm = 38.3176, GNorm = 1.9222, lr_0 = 1.0000e-04\n",
      "Loss = 4.7968e-01, PNorm = 38.3216, GNorm = 2.9450, lr_0 = 1.0000e-04\n",
      "Loss = 4.2563e-01, PNorm = 38.3246, GNorm = 1.4418, lr_0 = 1.0000e-04\n",
      "Loss = 4.6466e-01, PNorm = 38.3280, GNorm = 1.8551, lr_0 = 1.0000e-04\n",
      "Loss = 4.9713e-01, PNorm = 38.3328, GNorm = 1.2557, lr_0 = 1.0000e-04\n",
      "Loss = 4.7564e-01, PNorm = 38.3369, GNorm = 1.9997, lr_0 = 1.0000e-04\n",
      "Loss = 4.8930e-01, PNorm = 38.3415, GNorm = 1.4134, lr_0 = 1.0000e-04\n",
      "Loss = 4.4127e-01, PNorm = 38.3456, GNorm = 2.4341, lr_0 = 1.0000e-04\n",
      "Loss = 4.4486e-01, PNorm = 38.3482, GNorm = 1.2868, lr_0 = 1.0000e-04\n",
      "Loss = 4.2533e-01, PNorm = 38.3516, GNorm = 2.1618, lr_0 = 1.0000e-04\n",
      "Loss = 4.7868e-01, PNorm = 38.3562, GNorm = 1.6746, lr_0 = 1.0000e-04\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [03:08<02:34, 17.15s/it]Epoch 11\n",
      "Loss = 4.0318e-01, PNorm = 38.3606, GNorm = 2.0413, lr_0 = 1.0000e-04\n",
      "Loss = 4.6054e-01, PNorm = 38.3641, GNorm = 2.8709, lr_0 = 1.0000e-04\n",
      "Loss = 4.6379e-01, PNorm = 38.3690, GNorm = 2.5980, lr_0 = 1.0000e-04\n",
      "Loss = 4.8578e-01, PNorm = 38.3741, GNorm = 3.5964, lr_0 = 1.0000e-04\n",
      "Loss = 4.4758e-01, PNorm = 38.3779, GNorm = 1.8092, lr_0 = 1.0000e-04\n",
      "Loss = 3.9480e-01, PNorm = 38.3816, GNorm = 1.9438, lr_0 = 1.0000e-04\n",
      "Loss = 4.3720e-01, PNorm = 38.3857, GNorm = 3.6234, lr_0 = 1.0000e-04\n",
      "Loss = 3.4203e-01, PNorm = 38.3898, GNorm = 2.0008, lr_0 = 1.0000e-04\n",
      "Loss = 4.5742e-01, PNorm = 38.3940, GNorm = 5.4786, lr_0 = 1.0000e-04\n",
      "Loss = 4.5588e-01, PNorm = 38.3984, GNorm = 1.8536, lr_0 = 1.0000e-04\n",
      "Loss = 4.5194e-01, PNorm = 38.4025, GNorm = 1.3046, lr_0 = 1.0000e-04\n",
      "Loss = 4.5710e-01, PNorm = 38.4062, GNorm = 1.6184, lr_0 = 1.0000e-04\n",
      "Loss = 4.8213e-01, PNorm = 38.4099, GNorm = 1.7019, lr_0 = 1.0000e-04\n",
      "Loss = 4.6384e-01, PNorm = 38.4143, GNorm = 1.6884, lr_0 = 1.0000e-04\n",
      "Loss = 4.6894e-01, PNorm = 38.4186, GNorm = 2.3669, lr_0 = 1.0000e-04\n",
      "Loss = 4.1892e-01, PNorm = 38.4226, GNorm = 2.0011, lr_0 = 1.0000e-04\n",
      "Loss = 4.0965e-01, PNorm = 38.4268, GNorm = 2.4816, lr_0 = 1.0000e-04\n",
      "Loss = 5.0182e-01, PNorm = 38.4310, GNorm = 1.6759, lr_0 = 1.0000e-04\n",
      "Loss = 4.7399e-01, PNorm = 38.4342, GNorm = 1.4827, lr_0 = 1.0000e-04\n",
      "Loss = 4.7767e-01, PNorm = 38.4378, GNorm = 2.3321, lr_0 = 1.0000e-04\n",
      "Loss = 4.9919e-01, PNorm = 38.4435, GNorm = 3.9129, lr_0 = 1.0000e-04\n",
      "Loss = 4.8134e-01, PNorm = 38.4492, GNorm = 3.1708, lr_0 = 1.0000e-04\n",
      "Loss = 4.4106e-01, PNorm = 38.4542, GNorm = 4.0935, lr_0 = 1.0000e-04\n",
      "Loss = 4.5370e-01, PNorm = 38.4588, GNorm = 2.7320, lr_0 = 1.0000e-04\n",
      "Loss = 3.9317e-01, PNorm = 38.4630, GNorm = 2.1263, lr_0 = 1.0000e-04\n",
      "Loss = 4.7791e-01, PNorm = 38.4671, GNorm = 2.2774, lr_0 = 1.0000e-04\n",
      "Loss = 4.4930e-01, PNorm = 38.4706, GNorm = 3.5438, lr_0 = 1.0000e-04\n",
      "Loss = 5.1055e-01, PNorm = 38.4736, GNorm = 2.6249, lr_0 = 1.0000e-04\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [03:26<02:19, 17.38s/it]Epoch 12\n",
      "Loss = 4.3805e-01, PNorm = 38.4764, GNorm = 4.0680, lr_0 = 1.0000e-04\n",
      "Loss = 4.4009e-01, PNorm = 38.4800, GNorm = 1.5458, lr_0 = 1.0000e-04\n",
      "Loss = 4.0494e-01, PNorm = 38.4845, GNorm = 3.9586, lr_0 = 1.0000e-04\n",
      "Loss = 4.8491e-01, PNorm = 38.4884, GNorm = 2.7248, lr_0 = 1.0000e-04\n",
      "Loss = 4.2002e-01, PNorm = 38.4926, GNorm = 2.0397, lr_0 = 1.0000e-04\n",
      "Loss = 4.5405e-01, PNorm = 38.4974, GNorm = 1.8907, lr_0 = 1.0000e-04\n",
      "Loss = 4.4493e-01, PNorm = 38.5017, GNorm = 1.5108, lr_0 = 1.0000e-04\n",
      "Loss = 4.4889e-01, PNorm = 38.5058, GNorm = 2.5690, lr_0 = 1.0000e-04\n",
      "Loss = 4.5557e-01, PNorm = 38.5104, GNorm = 1.9655, lr_0 = 1.0000e-04\n",
      "Loss = 4.7008e-01, PNorm = 38.5144, GNorm = 2.5758, lr_0 = 1.0000e-04\n",
      "Loss = 4.7635e-01, PNorm = 38.5187, GNorm = 2.1082, lr_0 = 1.0000e-04\n",
      "Loss = 4.9943e-01, PNorm = 38.5230, GNorm = 1.7032, lr_0 = 1.0000e-04\n",
      "Loss = 4.3137e-01, PNorm = 38.5267, GNorm = 1.7679, lr_0 = 1.0000e-04\n",
      "Loss = 4.8617e-01, PNorm = 38.5300, GNorm = 3.1683, lr_0 = 1.0000e-04\n",
      "Loss = 4.4307e-01, PNorm = 38.5331, GNorm = 1.8238, lr_0 = 1.0000e-04\n",
      "Loss = 4.0967e-01, PNorm = 38.5372, GNorm = 2.8867, lr_0 = 1.0000e-04\n",
      "Loss = 3.9449e-01, PNorm = 38.5421, GNorm = 2.4583, lr_0 = 1.0000e-04\n",
      "Loss = 3.8889e-01, PNorm = 38.5455, GNorm = 2.6343, lr_0 = 1.0000e-04\n",
      "Loss = 4.1921e-01, PNorm = 38.5497, GNorm = 1.9829, lr_0 = 1.0000e-04\n",
      "Loss = 4.4932e-01, PNorm = 38.5537, GNorm = 2.2273, lr_0 = 1.0000e-04\n",
      "Loss = 4.7785e-01, PNorm = 38.5571, GNorm = 1.3105, lr_0 = 1.0000e-04\n",
      "Loss = 4.7745e-01, PNorm = 38.5604, GNorm = 1.4352, lr_0 = 1.0000e-04\n",
      "Loss = 4.5902e-01, PNorm = 38.5648, GNorm = 3.7546, lr_0 = 1.0000e-04\n",
      "Loss = 4.2716e-01, PNorm = 38.5706, GNorm = 2.1169, lr_0 = 1.0000e-04\n",
      "Loss = 4.2872e-01, PNorm = 38.5752, GNorm = 2.5467, lr_0 = 1.0000e-04\n",
      "Loss = 4.8707e-01, PNorm = 38.5780, GNorm = 3.1600, lr_0 = 1.0000e-04\n",
      "Loss = 4.9082e-01, PNorm = 38.5815, GNorm = 3.0083, lr_0 = 1.0000e-04\n",
      "Loss = 3.9024e-01, PNorm = 38.5848, GNorm = 1.6983, lr_0 = 1.0000e-04\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [03:41<01:55, 16.57s/it]Epoch 13\n",
      "Loss = 4.2480e-01, PNorm = 38.5891, GNorm = 2.9718, lr_0 = 1.0000e-04\n",
      "Loss = 4.0200e-01, PNorm = 38.5928, GNorm = 3.4701, lr_0 = 1.0000e-04\n",
      "Loss = 4.1483e-01, PNorm = 38.5967, GNorm = 1.0103, lr_0 = 1.0000e-04\n",
      "Loss = 4.2197e-01, PNorm = 38.6010, GNorm = 1.7051, lr_0 = 1.0000e-04\n",
      "Loss = 4.6526e-01, PNorm = 38.6057, GNorm = 1.4205, lr_0 = 1.0000e-04\n",
      "Loss = 4.5816e-01, PNorm = 38.6101, GNorm = 2.3047, lr_0 = 1.0000e-04\n",
      "Loss = 4.0054e-01, PNorm = 38.6142, GNorm = 2.5427, lr_0 = 1.0000e-04\n",
      "Loss = 4.6332e-01, PNorm = 38.6175, GNorm = 1.9042, lr_0 = 1.0000e-04\n",
      "Loss = 4.2931e-01, PNorm = 38.6212, GNorm = 1.7532, lr_0 = 1.0000e-04\n",
      "Loss = 4.2045e-01, PNorm = 38.6255, GNorm = 1.2752, lr_0 = 1.0000e-04\n",
      "Loss = 3.9844e-01, PNorm = 38.6300, GNorm = 2.3328, lr_0 = 1.0000e-04\n",
      "Loss = 4.6816e-01, PNorm = 38.6339, GNorm = 3.6736, lr_0 = 1.0000e-04\n",
      "Loss = 4.7199e-01, PNorm = 38.6384, GNorm = 2.6689, lr_0 = 1.0000e-04\n",
      "Loss = 4.0164e-01, PNorm = 38.6420, GNorm = 1.8372, lr_0 = 1.0000e-04\n",
      "Loss = 4.7559e-01, PNorm = 38.6465, GNorm = 2.6133, lr_0 = 1.0000e-04\n",
      "Loss = 4.4061e-01, PNorm = 38.6505, GNorm = 2.0367, lr_0 = 1.0000e-04\n",
      "Loss = 4.4192e-01, PNorm = 38.6538, GNorm = 1.9474, lr_0 = 1.0000e-04\n",
      "Loss = 4.3099e-01, PNorm = 38.6577, GNorm = 2.2879, lr_0 = 1.0000e-04\n",
      "Loss = 3.7900e-01, PNorm = 38.6621, GNorm = 2.8012, lr_0 = 1.0000e-04\n",
      "Loss = 5.0905e-01, PNorm = 38.6656, GNorm = 3.2260, lr_0 = 1.0000e-04\n",
      "Loss = 4.1549e-01, PNorm = 38.6692, GNorm = 1.9472, lr_0 = 1.0000e-04\n",
      "Loss = 4.7323e-01, PNorm = 38.6726, GNorm = 2.7379, lr_0 = 1.0000e-04\n",
      "Loss = 4.4548e-01, PNorm = 38.6760, GNorm = 1.5667, lr_0 = 1.0000e-04\n",
      "Loss = 4.3288e-01, PNorm = 38.6793, GNorm = 2.3628, lr_0 = 1.0000e-04\n",
      "Loss = 4.5260e-01, PNorm = 38.6829, GNorm = 1.2841, lr_0 = 1.0000e-04\n",
      "Loss = 4.8337e-01, PNorm = 38.6871, GNorm = 2.4226, lr_0 = 1.0000e-04\n",
      "Loss = 4.3785e-01, PNorm = 38.6906, GNorm = 2.4381, lr_0 = 1.0000e-04\n",
      "Loss = 4.7019e-01, PNorm = 38.6932, GNorm = 5.3754, lr_0 = 1.0000e-04\n",
      "Loss = 1.3614e-01, PNorm = 38.6934, GNorm = 1.8794, lr_0 = 1.0000e-04\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [03:57<01:38, 16.45s/it]Epoch 14\n",
      "Loss = 4.4050e-01, PNorm = 38.6966, GNorm = 2.3385, lr_0 = 1.0000e-04\n",
      "Loss = 5.0205e-01, PNorm = 38.6997, GNorm = 3.5123, lr_0 = 1.0000e-04\n",
      "Loss = 3.8889e-01, PNorm = 38.7033, GNorm = 2.2801, lr_0 = 1.0000e-04\n",
      "Loss = 4.4564e-01, PNorm = 38.7071, GNorm = 1.6204, lr_0 = 1.0000e-04\n",
      "Loss = 4.0884e-01, PNorm = 38.7107, GNorm = 2.0139, lr_0 = 1.0000e-04\n",
      "Loss = 4.1637e-01, PNorm = 38.7147, GNorm = 2.3415, lr_0 = 1.0000e-04\n",
      "Loss = 4.2535e-01, PNorm = 38.7182, GNorm = 1.8564, lr_0 = 1.0000e-04\n",
      "Loss = 4.7779e-01, PNorm = 38.7231, GNorm = 3.1103, lr_0 = 1.0000e-04\n",
      "Loss = 4.4834e-01, PNorm = 38.7280, GNorm = 1.7407, lr_0 = 1.0000e-04\n",
      "Loss = 3.9644e-01, PNorm = 38.7325, GNorm = 2.8400, lr_0 = 1.0000e-04\n",
      "Loss = 3.9974e-01, PNorm = 38.7357, GNorm = 1.5507, lr_0 = 1.0000e-04\n",
      "Loss = 4.5550e-01, PNorm = 38.7389, GNorm = 1.7120, lr_0 = 1.0000e-04\n",
      "Loss = 4.1911e-01, PNorm = 38.7424, GNorm = 2.0985, lr_0 = 1.0000e-04\n",
      "Loss = 4.7819e-01, PNorm = 38.7460, GNorm = 2.5928, lr_0 = 1.0000e-04\n",
      "Loss = 4.7109e-01, PNorm = 38.7507, GNorm = 1.5746, lr_0 = 1.0000e-04\n",
      "Loss = 4.5427e-01, PNorm = 38.7550, GNorm = 1.6136, lr_0 = 1.0000e-04\n",
      "Loss = 4.2328e-01, PNorm = 38.7586, GNorm = 1.4030, lr_0 = 1.0000e-04\n",
      "Loss = 4.2400e-01, PNorm = 38.7614, GNorm = 1.5036, lr_0 = 1.0000e-04\n",
      "Loss = 4.1925e-01, PNorm = 38.7651, GNorm = 1.4930, lr_0 = 1.0000e-04\n",
      "Loss = 3.8366e-01, PNorm = 38.7693, GNorm = 3.3279, lr_0 = 1.0000e-04\n",
      "Loss = 4.7310e-01, PNorm = 38.7727, GNorm = 2.4275, lr_0 = 1.0000e-04\n",
      "Loss = 3.9296e-01, PNorm = 38.7752, GNorm = 1.2281, lr_0 = 1.0000e-04\n",
      "Loss = 4.5951e-01, PNorm = 38.7793, GNorm = 2.7427, lr_0 = 1.0000e-04\n",
      "Loss = 4.6705e-01, PNorm = 38.7836, GNorm = 1.8915, lr_0 = 1.0000e-04\n",
      "Loss = 3.7026e-01, PNorm = 38.7874, GNorm = 2.1085, lr_0 = 1.0000e-04\n",
      "Loss = 3.6374e-01, PNorm = 38.7915, GNorm = 2.3268, lr_0 = 1.0000e-04\n",
      "Loss = 3.8887e-01, PNorm = 38.7948, GNorm = 1.9917, lr_0 = 1.0000e-04\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [04:14<01:23, 16.63s/it]Epoch 15\n",
      "Loss = 5.0715e-01, PNorm = 38.7993, GNorm = 3.6011, lr_0 = 1.0000e-04\n",
      "Loss = 4.0616e-01, PNorm = 38.8035, GNorm = 1.6075, lr_0 = 1.0000e-04\n",
      "Loss = 3.6950e-01, PNorm = 38.8080, GNorm = 2.8795, lr_0 = 1.0000e-04\n",
      "Loss = 4.2229e-01, PNorm = 38.8120, GNorm = 1.8411, lr_0 = 1.0000e-04\n",
      "Loss = 4.5455e-01, PNorm = 38.8167, GNorm = 1.5564, lr_0 = 1.0000e-04\n",
      "Loss = 4.2221e-01, PNorm = 38.8209, GNorm = 3.7077, lr_0 = 1.0000e-04\n",
      "Loss = 4.6424e-01, PNorm = 38.8254, GNorm = 2.4845, lr_0 = 1.0000e-04\n",
      "Loss = 4.3259e-01, PNorm = 38.8292, GNorm = 1.6806, lr_0 = 1.0000e-04\n",
      "Loss = 4.2466e-01, PNorm = 38.8330, GNorm = 1.6275, lr_0 = 1.0000e-04\n",
      "Loss = 4.1733e-01, PNorm = 38.8366, GNorm = 1.8837, lr_0 = 1.0000e-04\n",
      "Loss = 4.1089e-01, PNorm = 38.8389, GNorm = 1.7149, lr_0 = 1.0000e-04\n",
      "Loss = 5.0813e-01, PNorm = 38.8422, GNorm = 1.7000, lr_0 = 1.0000e-04\n",
      "Loss = 3.7866e-01, PNorm = 38.8453, GNorm = 1.8058, lr_0 = 1.0000e-04\n",
      "Loss = 4.0273e-01, PNorm = 38.8496, GNorm = 1.7233, lr_0 = 1.0000e-04\n",
      "Loss = 4.2083e-01, PNorm = 38.8545, GNorm = 2.7289, lr_0 = 1.0000e-04\n",
      "Loss = 4.7530e-01, PNorm = 38.8585, GNorm = 3.3030, lr_0 = 1.0000e-04\n",
      "Loss = 4.4297e-01, PNorm = 38.8634, GNorm = 1.2105, lr_0 = 1.0000e-04\n",
      "Loss = 4.4964e-01, PNorm = 38.8669, GNorm = 1.4767, lr_0 = 1.0000e-04\n",
      "Loss = 4.2516e-01, PNorm = 38.8704, GNorm = 1.8433, lr_0 = 1.0000e-04\n",
      "Loss = 4.2700e-01, PNorm = 38.8732, GNorm = 1.9724, lr_0 = 1.0000e-04\n",
      "Loss = 3.6481e-01, PNorm = 38.8755, GNorm = 1.3578, lr_0 = 1.0000e-04\n",
      "Loss = 4.1526e-01, PNorm = 38.8794, GNorm = 1.7678, lr_0 = 1.0000e-04\n",
      "Loss = 3.8991e-01, PNorm = 38.8835, GNorm = 1.5440, lr_0 = 1.0000e-04\n",
      "Loss = 3.9229e-01, PNorm = 38.8875, GNorm = 1.6923, lr_0 = 1.0000e-04\n",
      "Loss = 4.1683e-01, PNorm = 38.8915, GNorm = 2.6933, lr_0 = 1.0000e-04\n",
      "Loss = 4.1073e-01, PNorm = 38.8951, GNorm = 2.2769, lr_0 = 1.0000e-04\n",
      "Loss = 3.8734e-01, PNorm = 38.8984, GNorm = 1.6531, lr_0 = 1.0000e-04\n",
      "Loss = 4.3138e-01, PNorm = 38.9009, GNorm = 1.5870, lr_0 = 1.0000e-04\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [04:32<01:08, 17.10s/it]Epoch 16\n",
      "Loss = 4.1344e-01, PNorm = 38.9041, GNorm = 1.2822, lr_0 = 1.0000e-04\n",
      "Loss = 4.1318e-01, PNorm = 38.9074, GNorm = 1.6137, lr_0 = 1.0000e-04\n",
      "Loss = 4.3990e-01, PNorm = 38.9112, GNorm = 1.5091, lr_0 = 1.0000e-04\n",
      "Loss = 3.8387e-01, PNorm = 38.9145, GNorm = 1.3653, lr_0 = 1.0000e-04\n",
      "Loss = 4.2679e-01, PNorm = 38.9180, GNorm = 2.0032, lr_0 = 1.0000e-04\n",
      "Loss = 3.7318e-01, PNorm = 38.9217, GNorm = 3.4655, lr_0 = 1.0000e-04\n",
      "Loss = 4.1200e-01, PNorm = 38.9254, GNorm = 3.1358, lr_0 = 1.0000e-04\n",
      "Loss = 3.8930e-01, PNorm = 38.9291, GNorm = 2.5272, lr_0 = 1.0000e-04\n",
      "Loss = 4.3391e-01, PNorm = 38.9324, GNorm = 2.4190, lr_0 = 1.0000e-04\n",
      "Loss = 4.7552e-01, PNorm = 38.9358, GNorm = 2.1688, lr_0 = 1.0000e-04\n",
      "Loss = 4.3949e-01, PNorm = 38.9401, GNorm = 3.6099, lr_0 = 1.0000e-04\n",
      "Loss = 4.0524e-01, PNorm = 38.9443, GNorm = 3.2041, lr_0 = 1.0000e-04\n",
      "Loss = 4.0051e-01, PNorm = 38.9478, GNorm = 1.6882, lr_0 = 1.0000e-04\n",
      "Loss = 4.3854e-01, PNorm = 38.9511, GNorm = 1.9671, lr_0 = 1.0000e-04\n",
      "Loss = 3.6071e-01, PNorm = 38.9549, GNorm = 2.2838, lr_0 = 1.0000e-04\n",
      "Loss = 4.2504e-01, PNorm = 38.9574, GNorm = 2.3171, lr_0 = 1.0000e-04\n",
      "Loss = 4.1415e-01, PNorm = 38.9616, GNorm = 2.2714, lr_0 = 1.0000e-04\n",
      "Loss = 3.9073e-01, PNorm = 38.9646, GNorm = 3.2347, lr_0 = 1.0000e-04\n",
      "Loss = 4.1516e-01, PNorm = 38.9682, GNorm = 2.3678, lr_0 = 1.0000e-04\n",
      "Loss = 3.9900e-01, PNorm = 38.9720, GNorm = 2.1224, lr_0 = 1.0000e-04\n",
      "Loss = 4.3129e-01, PNorm = 38.9759, GNorm = 1.3614, lr_0 = 1.0000e-04\n",
      "Loss = 4.2833e-01, PNorm = 38.9801, GNorm = 2.3050, lr_0 = 1.0000e-04\n",
      "Loss = 4.3867e-01, PNorm = 38.9841, GNorm = 1.6689, lr_0 = 1.0000e-04\n",
      "Loss = 3.9798e-01, PNorm = 38.9882, GNorm = 1.4382, lr_0 = 1.0000e-04\n",
      "Loss = 3.9119e-01, PNorm = 38.9919, GNorm = 2.5494, lr_0 = 1.0000e-04\n",
      "Loss = 4.4036e-01, PNorm = 38.9956, GNorm = 2.2443, lr_0 = 1.0000e-04\n",
      "Loss = 4.2811e-01, PNorm = 39.0000, GNorm = 1.3659, lr_0 = 1.0000e-04\n",
      "Loss = 4.3092e-01, PNorm = 39.0043, GNorm = 2.1394, lr_0 = 1.0000e-04\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [04:49<00:51, 17.04s/it]Epoch 17\n",
      "Loss = 3.3719e-01, PNorm = 39.0097, GNorm = 3.0845, lr_0 = 1.0000e-04\n",
      "Loss = 4.2610e-01, PNorm = 39.0134, GNorm = 2.5203, lr_0 = 1.0000e-04\n",
      "Loss = 4.7261e-01, PNorm = 39.0166, GNorm = 2.3985, lr_0 = 1.0000e-04\n",
      "Loss = 3.8454e-01, PNorm = 39.0209, GNorm = 2.8175, lr_0 = 1.0000e-04\n",
      "Loss = 3.9848e-01, PNorm = 39.0243, GNorm = 1.9937, lr_0 = 1.0000e-04\n",
      "Loss = 3.9375e-01, PNorm = 39.0281, GNorm = 1.4011, lr_0 = 1.0000e-04\n",
      "Loss = 4.2652e-01, PNorm = 39.0321, GNorm = 2.8534, lr_0 = 1.0000e-04\n",
      "Loss = 4.3552e-01, PNorm = 39.0365, GNorm = 4.3416, lr_0 = 1.0000e-04\n",
      "Loss = 4.2726e-01, PNorm = 39.0403, GNorm = 3.0906, lr_0 = 1.0000e-04\n",
      "Loss = 3.9365e-01, PNorm = 39.0449, GNorm = 2.3527, lr_0 = 1.0000e-04\n",
      "Loss = 3.8385e-01, PNorm = 39.0493, GNorm = 1.9669, lr_0 = 1.0000e-04\n",
      "Loss = 4.0302e-01, PNorm = 39.0535, GNorm = 3.4980, lr_0 = 1.0000e-04\n",
      "Loss = 4.1336e-01, PNorm = 39.0571, GNorm = 3.0824, lr_0 = 1.0000e-04\n",
      "Loss = 4.1003e-01, PNorm = 39.0602, GNorm = 2.4507, lr_0 = 1.0000e-04\n",
      "Loss = 3.9152e-01, PNorm = 39.0631, GNorm = 1.4463, lr_0 = 1.0000e-04\n",
      "Loss = 4.2319e-01, PNorm = 39.0663, GNorm = 1.9993, lr_0 = 1.0000e-04\n",
      "Loss = 4.1623e-01, PNorm = 39.0696, GNorm = 3.9793, lr_0 = 1.0000e-04\n",
      "Loss = 4.1542e-01, PNorm = 39.0730, GNorm = 2.8909, lr_0 = 1.0000e-04\n",
      "Loss = 3.5905e-01, PNorm = 39.0759, GNorm = 1.9071, lr_0 = 1.0000e-04\n",
      "Loss = 3.2340e-01, PNorm = 39.0791, GNorm = 2.5991, lr_0 = 1.0000e-04\n",
      "Loss = 3.9009e-01, PNorm = 39.0821, GNorm = 1.8032, lr_0 = 1.0000e-04\n",
      "Loss = 4.6556e-01, PNorm = 39.0851, GNorm = 2.2330, lr_0 = 1.0000e-04\n",
      "Loss = 4.4395e-01, PNorm = 39.0878, GNorm = 1.4861, lr_0 = 1.0000e-04\n",
      "Loss = 3.9192e-01, PNorm = 39.0920, GNorm = 3.6780, lr_0 = 1.0000e-04\n",
      "Loss = 4.0174e-01, PNorm = 39.0953, GNorm = 2.8193, lr_0 = 1.0000e-04\n",
      "Loss = 4.8755e-01, PNorm = 39.0971, GNorm = 1.9701, lr_0 = 1.0000e-04\n",
      "Loss = 4.2247e-01, PNorm = 39.0997, GNorm = 3.0571, lr_0 = 1.0000e-04\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [05:06<00:34, 17.06s/it]Epoch 18\n",
      "Loss = 5.5659e-01, PNorm = 39.1032, GNorm = 3.2681, lr_0 = 1.0000e-04\n",
      "Loss = 4.1761e-01, PNorm = 39.1073, GNorm = 2.1090, lr_0 = 1.0000e-04\n",
      "Loss = 4.1630e-01, PNorm = 39.1113, GNorm = 1.4632, lr_0 = 1.0000e-04\n",
      "Loss = 4.2039e-01, PNorm = 39.1145, GNorm = 2.4924, lr_0 = 1.0000e-04\n",
      "Loss = 3.8108e-01, PNorm = 39.1182, GNorm = 1.9164, lr_0 = 1.0000e-04\n",
      "Loss = 4.1060e-01, PNorm = 39.1220, GNorm = 3.0314, lr_0 = 1.0000e-04\n",
      "Loss = 4.0342e-01, PNorm = 39.1263, GNorm = 1.6734, lr_0 = 1.0000e-04\n",
      "Loss = 3.8121e-01, PNorm = 39.1298, GNorm = 1.6746, lr_0 = 1.0000e-04\n",
      "Loss = 4.2672e-01, PNorm = 39.1331, GNorm = 3.8536, lr_0 = 1.0000e-04\n",
      "Loss = 4.3746e-01, PNorm = 39.1367, GNorm = 2.9553, lr_0 = 1.0000e-04\n",
      "Loss = 4.1183e-01, PNorm = 39.1401, GNorm = 3.1768, lr_0 = 1.0000e-04\n",
      "Loss = 4.0331e-01, PNorm = 39.1423, GNorm = 3.8069, lr_0 = 1.0000e-04\n",
      "Loss = 4.1049e-01, PNorm = 39.1452, GNorm = 1.8727, lr_0 = 1.0000e-04\n",
      "Loss = 4.0143e-01, PNorm = 39.1492, GNorm = 2.2696, lr_0 = 1.0000e-04\n",
      "Loss = 3.9531e-01, PNorm = 39.1531, GNorm = 1.4897, lr_0 = 1.0000e-04\n",
      "Loss = 4.1480e-01, PNorm = 39.1571, GNorm = 2.3999, lr_0 = 1.0000e-04\n",
      "Loss = 4.3922e-01, PNorm = 39.1612, GNorm = 2.0601, lr_0 = 1.0000e-04\n",
      "Loss = 3.8985e-01, PNorm = 39.1651, GNorm = 1.2311, lr_0 = 1.0000e-04\n",
      "Loss = 3.8830e-01, PNorm = 39.1689, GNorm = 2.8597, lr_0 = 1.0000e-04\n",
      "Loss = 3.8117e-01, PNorm = 39.1725, GNorm = 1.7093, lr_0 = 1.0000e-04\n",
      "Loss = 4.0771e-01, PNorm = 39.1759, GNorm = 3.0175, lr_0 = 1.0000e-04\n",
      "Loss = 4.2191e-01, PNorm = 39.1794, GNorm = 2.6605, lr_0 = 1.0000e-04\n",
      "Loss = 3.8184e-01, PNorm = 39.1833, GNorm = 2.8618, lr_0 = 1.0000e-04\n",
      "Loss = 3.9628e-01, PNorm = 39.1873, GNorm = 3.2345, lr_0 = 1.0000e-04\n",
      "Loss = 3.9469e-01, PNorm = 39.1915, GNorm = 1.5484, lr_0 = 1.0000e-04\n",
      "Loss = 3.8781e-01, PNorm = 39.1948, GNorm = 2.7192, lr_0 = 1.0000e-04\n",
      "Loss = 4.1024e-01, PNorm = 39.1981, GNorm = 1.2645, lr_0 = 1.0000e-04\n",
      "Loss = 4.0159e-01, PNorm = 39.2014, GNorm = 2.2357, lr_0 = 1.0000e-04\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [05:22<00:16, 16.51s/it]Epoch 19\n",
      "Loss = 4.4379e-01, PNorm = 39.2045, GNorm = 1.9912, lr_0 = 1.0000e-04\n",
      "Loss = 4.4460e-01, PNorm = 39.2071, GNorm = 1.6137, lr_0 = 1.0000e-04\n",
      "Loss = 3.8371e-01, PNorm = 39.2099, GNorm = 2.1609, lr_0 = 1.0000e-04\n",
      "Loss = 4.2128e-01, PNorm = 39.2121, GNorm = 2.0595, lr_0 = 1.0000e-04\n",
      "Loss = 3.5328e-01, PNorm = 39.2152, GNorm = 2.0130, lr_0 = 1.0000e-04\n",
      "Loss = 4.2496e-01, PNorm = 39.2193, GNorm = 4.3595, lr_0 = 1.0000e-04\n",
      "Loss = 3.6276e-01, PNorm = 39.2240, GNorm = 2.1661, lr_0 = 1.0000e-04\n",
      "Loss = 3.6690e-01, PNorm = 39.2280, GNorm = 2.0488, lr_0 = 1.0000e-04\n",
      "Loss = 4.1850e-01, PNorm = 39.2318, GNorm = 2.1848, lr_0 = 1.0000e-04\n",
      "Loss = 4.1834e-01, PNorm = 39.2347, GNorm = 3.0337, lr_0 = 1.0000e-04\n",
      "Loss = 3.3737e-01, PNorm = 39.2372, GNorm = 1.6916, lr_0 = 1.0000e-04\n",
      "Loss = 3.8192e-01, PNorm = 39.2395, GNorm = 1.9404, lr_0 = 1.0000e-04\n",
      "Loss = 4.0841e-01, PNorm = 39.2434, GNorm = 1.9682, lr_0 = 1.0000e-04\n",
      "Loss = 3.8157e-01, PNorm = 39.2466, GNorm = 2.0104, lr_0 = 1.0000e-04\n",
      "Loss = 4.0930e-01, PNorm = 39.2496, GNorm = 4.0807, lr_0 = 1.0000e-04\n",
      "Loss = 4.0826e-01, PNorm = 39.2535, GNorm = 3.3138, lr_0 = 1.0000e-04\n",
      "Loss = 3.7021e-01, PNorm = 39.2567, GNorm = 1.4284, lr_0 = 1.0000e-04\n",
      "Loss = 4.0622e-01, PNorm = 39.2606, GNorm = 1.9263, lr_0 = 1.0000e-04\n",
      "Loss = 4.2851e-01, PNorm = 39.2637, GNorm = 1.3286, lr_0 = 1.0000e-04\n",
      "Loss = 3.9814e-01, PNorm = 39.2669, GNorm = 3.6324, lr_0 = 1.0000e-04\n",
      "Loss = 3.7976e-01, PNorm = 39.2707, GNorm = 1.7793, lr_0 = 1.0000e-04\n",
      "Loss = 4.1497e-01, PNorm = 39.2744, GNorm = 2.7514, lr_0 = 1.0000e-04\n",
      "Loss = 3.8710e-01, PNorm = 39.2784, GNorm = 2.4332, lr_0 = 1.0000e-04\n",
      "Loss = 3.5584e-01, PNorm = 39.2824, GNorm = 2.7339, lr_0 = 1.0000e-04\n",
      "Loss = 3.5540e-01, PNorm = 39.2859, GNorm = 1.6426, lr_0 = 1.0000e-04\n",
      "Loss = 3.7337e-01, PNorm = 39.2890, GNorm = 2.2621, lr_0 = 1.0000e-04\n",
      "Loss = 3.9300e-01, PNorm = 39.2924, GNorm = 1.3501, lr_0 = 1.0000e-04\n",
      "Loss = 3.9620e-01, PNorm = 39.2964, GNorm = 1.5788, lr_0 = 1.0000e-04\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [05:38<00:00, 16.91s/it]\n",
      "qsprpred - WARNING - Early stopping did not yield a best model, using last model instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is caused by either ... or by ...\n",
      "P00533\n",
      "0\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total size = 13,860\n",
      "Fitting scaler\n",
      "Number of parameters = 356,706\n",
      "Moving trained model to cuda\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 1.0747e+00, PNorm = 34.0946, GNorm = 2.5035, lr_0 = 1.1787e-04\n",
      "Loss = 1.0146e+00, PNorm = 34.0948, GNorm = 2.8326, lr_0 = 1.3412e-04\n",
      "Loss = 9.4923e-01, PNorm = 34.0956, GNorm = 3.9701, lr_0 = 1.5036e-04\n",
      "Loss = 1.0028e+00, PNorm = 34.0974, GNorm = 3.4168, lr_0 = 1.6661e-04\n",
      "Loss = 9.3447e-01, PNorm = 34.1008, GNorm = 2.3995, lr_0 = 1.8285e-04\n",
      "Loss = 1.0220e+00, PNorm = 34.1052, GNorm = 2.1576, lr_0 = 1.9910e-04\n",
      "Loss = 9.3754e-01, PNorm = 34.1109, GNorm = 1.1340, lr_0 = 2.1534e-04\n",
      "Loss = 1.0059e+00, PNorm = 34.1172, GNorm = 6.4548, lr_0 = 2.3159e-04\n",
      "Loss = 8.8825e-01, PNorm = 34.1249, GNorm = 2.4476, lr_0 = 2.4783e-04\n",
      "Loss = 9.2004e-01, PNorm = 34.1352, GNorm = 1.2653, lr_0 = 2.6408e-04\n",
      "Loss = 8.7928e-01, PNorm = 34.1473, GNorm = 1.1705, lr_0 = 2.8032e-04\n",
      "Loss = 9.3702e-01, PNorm = 34.1603, GNorm = 2.7534, lr_0 = 2.9657e-04\n",
      "Loss = 8.9340e-01, PNorm = 34.1760, GNorm = 1.8875, lr_0 = 3.1282e-04\n",
      "Loss = 9.6562e-01, PNorm = 34.1903, GNorm = 9.1078, lr_0 = 3.2906e-04\n",
      "Loss = 1.0252e+00, PNorm = 34.2049, GNorm = 3.5727, lr_0 = 3.4531e-04\n",
      "Loss = 9.8084e-01, PNorm = 34.2216, GNorm = 3.1013, lr_0 = 3.6155e-04\n",
      "Loss = 9.6969e-01, PNorm = 34.2416, GNorm = 1.8510, lr_0 = 3.7780e-04\n",
      "Loss = 9.4402e-01, PNorm = 34.2640, GNorm = 2.1896, lr_0 = 3.9404e-04\n",
      "Loss = 9.1085e-01, PNorm = 34.2850, GNorm = 1.3129, lr_0 = 4.1029e-04\n",
      "Loss = 8.5977e-01, PNorm = 34.3124, GNorm = 1.6455, lr_0 = 4.2653e-04\n",
      "Loss = 7.8173e-01, PNorm = 34.3375, GNorm = 1.7464, lr_0 = 4.4278e-04\n",
      "Loss = 7.9323e-01, PNorm = 34.3658, GNorm = 2.4002, lr_0 = 4.5903e-04\n",
      "Loss = 8.1803e-01, PNorm = 34.3886, GNorm = 1.8902, lr_0 = 4.7527e-04\n",
      "Loss = 8.5296e-01, PNorm = 34.4123, GNorm = 2.3413, lr_0 = 4.9152e-04\n",
      "Loss = 8.0919e-01, PNorm = 34.4448, GNorm = 1.5841, lr_0 = 5.0776e-04\n",
      "Loss = 8.8636e-01, PNorm = 34.4810, GNorm = 3.1887, lr_0 = 5.2401e-04\n",
      "Loss = 7.1312e-01, PNorm = 34.5105, GNorm = 1.3156, lr_0 = 5.4025e-04\n",
      "  5%|â–Œ         | 1/20 [00:20<06:34, 20.76s/it]Epoch 1\n",
      "Loss = 8.0876e-01, PNorm = 34.5462, GNorm = 1.9608, lr_0 = 5.5812e-04\n",
      "Loss = 9.2176e-01, PNorm = 34.5827, GNorm = 1.8636, lr_0 = 5.7437e-04\n",
      "Loss = 8.5748e-01, PNorm = 34.6260, GNorm = 2.1118, lr_0 = 5.9061e-04\n",
      "Loss = 7.9760e-01, PNorm = 34.6703, GNorm = 0.8941, lr_0 = 6.0686e-04\n",
      "Loss = 8.1905e-01, PNorm = 34.7066, GNorm = 1.2368, lr_0 = 6.2310e-04\n",
      "Loss = 7.7652e-01, PNorm = 34.7453, GNorm = 1.3934, lr_0 = 6.3935e-04\n",
      "Loss = 7.5353e-01, PNorm = 34.7866, GNorm = 1.6522, lr_0 = 6.5560e-04\n",
      "Loss = 9.0923e-01, PNorm = 34.8348, GNorm = 4.2424, lr_0 = 6.7184e-04\n",
      "Loss = 7.8420e-01, PNorm = 34.8861, GNorm = 2.2020, lr_0 = 6.8809e-04\n",
      "Loss = 7.5354e-01, PNorm = 34.9352, GNorm = 1.9176, lr_0 = 7.0433e-04\n",
      "Loss = 6.7931e-01, PNorm = 34.9751, GNorm = 2.5618, lr_0 = 7.2058e-04\n",
      "Loss = 6.8721e-01, PNorm = 35.0165, GNorm = 2.7878, lr_0 = 7.3682e-04\n",
      "Loss = 7.8539e-01, PNorm = 35.0665, GNorm = 0.9026, lr_0 = 7.5307e-04\n",
      "Loss = 7.8250e-01, PNorm = 35.1185, GNorm = 5.6500, lr_0 = 7.6931e-04\n",
      "Loss = 7.9535e-01, PNorm = 35.1502, GNorm = 2.1236, lr_0 = 7.8556e-04\n",
      "Loss = 7.6723e-01, PNorm = 35.1903, GNorm = 1.2167, lr_0 = 8.0181e-04\n",
      "Loss = 8.5366e-01, PNorm = 35.2537, GNorm = 0.8945, lr_0 = 8.1805e-04\n",
      "Loss = 7.4746e-01, PNorm = 35.3046, GNorm = 0.5570, lr_0 = 8.3430e-04\n",
      "Loss = 7.2706e-01, PNorm = 35.3507, GNorm = 2.6109, lr_0 = 8.5054e-04\n",
      "Loss = 7.6630e-01, PNorm = 35.3927, GNorm = 2.2051, lr_0 = 8.6679e-04\n",
      "Loss = 8.2652e-01, PNorm = 35.4555, GNorm = 5.7013, lr_0 = 8.8303e-04\n",
      "Loss = 7.9895e-01, PNorm = 35.5068, GNorm = 1.0554, lr_0 = 8.9928e-04\n",
      "Loss = 7.0686e-01, PNorm = 35.5609, GNorm = 2.3168, lr_0 = 9.1552e-04\n",
      "Loss = 7.7063e-01, PNorm = 35.6203, GNorm = 3.1871, lr_0 = 9.3177e-04\n",
      "Loss = 7.7363e-01, PNorm = 35.6756, GNorm = 1.4859, lr_0 = 9.4801e-04\n",
      "Loss = 7.8291e-01, PNorm = 35.7482, GNorm = 0.6030, lr_0 = 9.6426e-04\n",
      "Loss = 7.0027e-01, PNorm = 35.8157, GNorm = 2.3104, lr_0 = 9.8051e-04\n",
      "Loss = 6.3464e-01, PNorm = 35.8789, GNorm = 1.2925, lr_0 = 9.9675e-04\n",
      " 10%|â–ˆ         | 2/20 [00:38<05:41, 18.98s/it]Epoch 2\n",
      "Loss = 8.8796e-01, PNorm = 35.9399, GNorm = 2.1598, lr_0 = 9.7537e-04\n",
      "Loss = 6.7393e-01, PNorm = 35.9925, GNorm = 1.6779, lr_0 = 9.4872e-04\n",
      "Loss = 7.0272e-01, PNorm = 36.0518, GNorm = 1.4047, lr_0 = 9.2279e-04\n",
      "Loss = 7.3484e-01, PNorm = 36.1040, GNorm = 1.8705, lr_0 = 8.9757e-04\n",
      "Loss = 6.7292e-01, PNorm = 36.1494, GNorm = 1.1330, lr_0 = 8.7304e-04\n",
      "Loss = 7.1033e-01, PNorm = 36.1954, GNorm = 1.6991, lr_0 = 8.4918e-04\n",
      "Loss = 7.2173e-01, PNorm = 36.2437, GNorm = 1.4273, lr_0 = 8.2598e-04\n",
      "Loss = 6.4918e-01, PNorm = 36.2850, GNorm = 1.0463, lr_0 = 8.0340e-04\n",
      "Loss = 6.7815e-01, PNorm = 36.3290, GNorm = 0.7402, lr_0 = 7.8145e-04\n",
      "Loss = 6.7435e-01, PNorm = 36.3642, GNorm = 0.5346, lr_0 = 7.6009e-04\n",
      "Loss = 7.1842e-01, PNorm = 36.4118, GNorm = 1.2536, lr_0 = 7.3932e-04\n",
      "Loss = 6.2288e-01, PNorm = 36.4577, GNorm = 1.6210, lr_0 = 7.1912e-04\n",
      "Loss = 6.6644e-01, PNorm = 36.4862, GNorm = 1.3052, lr_0 = 6.9946e-04\n",
      "Loss = 6.8295e-01, PNorm = 36.5210, GNorm = 2.2439, lr_0 = 6.8035e-04\n",
      "Loss = 6.2818e-01, PNorm = 36.5594, GNorm = 1.6274, lr_0 = 6.6176e-04\n",
      "Loss = 5.8887e-01, PNorm = 36.5942, GNorm = 1.8657, lr_0 = 6.4367e-04\n",
      "Loss = 5.3126e-01, PNorm = 36.6322, GNorm = 1.3156, lr_0 = 6.2608e-04\n",
      "Loss = 6.5684e-01, PNorm = 36.6656, GNorm = 1.6852, lr_0 = 6.0897e-04\n",
      "Loss = 6.0283e-01, PNorm = 36.6982, GNorm = 1.1877, lr_0 = 5.9233e-04\n",
      "Loss = 6.5295e-01, PNorm = 36.7350, GNorm = 0.7806, lr_0 = 5.7614e-04\n",
      "Loss = 6.0319e-01, PNorm = 36.7636, GNorm = 1.3932, lr_0 = 5.6040e-04\n",
      "Loss = 6.1523e-01, PNorm = 36.7886, GNorm = 1.1322, lr_0 = 5.4508e-04\n",
      "Loss = 6.0097e-01, PNorm = 36.8176, GNorm = 0.7300, lr_0 = 5.3019e-04\n",
      "Loss = 5.8343e-01, PNorm = 36.8443, GNorm = 0.9845, lr_0 = 5.1570e-04\n",
      "Loss = 6.9741e-01, PNorm = 36.8700, GNorm = 2.0189, lr_0 = 5.0160e-04\n",
      "Loss = 7.1085e-01, PNorm = 36.9039, GNorm = 2.3720, lr_0 = 4.8790e-04\n",
      "Loss = 6.4005e-01, PNorm = 36.9309, GNorm = 1.1096, lr_0 = 4.7456e-04\n",
      "Loss = 6.5025e-01, PNorm = 36.9489, GNorm = 1.3889, lr_0 = 4.6159e-04\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:55<05:10, 18.24s/it]Epoch 3\n",
      "Loss = 5.9616e-01, PNorm = 36.9681, GNorm = 1.6027, lr_0 = 4.4774e-04\n",
      "Loss = 5.6362e-01, PNorm = 36.9897, GNorm = 1.7804, lr_0 = 4.3550e-04\n",
      "Loss = 6.2033e-01, PNorm = 37.0166, GNorm = 2.1161, lr_0 = 4.2360e-04\n",
      "Loss = 7.1197e-01, PNorm = 37.0421, GNorm = 1.0621, lr_0 = 4.1202e-04\n",
      "Loss = 5.9351e-01, PNorm = 37.0657, GNorm = 2.4708, lr_0 = 4.0076e-04\n",
      "Loss = 5.2676e-01, PNorm = 37.0891, GNorm = 1.8038, lr_0 = 3.8981e-04\n",
      "Loss = 5.9188e-01, PNorm = 37.1078, GNorm = 0.8863, lr_0 = 3.7916e-04\n",
      "Loss = 5.7457e-01, PNorm = 37.1247, GNorm = 0.9405, lr_0 = 3.6880e-04\n",
      "Loss = 6.2932e-01, PNorm = 37.1409, GNorm = 2.8038, lr_0 = 3.5872e-04\n",
      "Loss = 6.2929e-01, PNorm = 37.1562, GNorm = 1.6974, lr_0 = 3.4891e-04\n",
      "Loss = 5.4052e-01, PNorm = 37.1764, GNorm = 1.7470, lr_0 = 3.3938e-04\n",
      "Loss = 5.9843e-01, PNorm = 37.1924, GNorm = 2.4861, lr_0 = 3.3011e-04\n",
      "Loss = 5.7684e-01, PNorm = 37.2071, GNorm = 1.8577, lr_0 = 3.2108e-04\n",
      "Loss = 5.9527e-01, PNorm = 37.2250, GNorm = 1.1669, lr_0 = 3.1231e-04\n",
      "Loss = 5.8202e-01, PNorm = 37.2423, GNorm = 0.9992, lr_0 = 3.0377e-04\n",
      "Loss = 5.6340e-01, PNorm = 37.2550, GNorm = 1.8732, lr_0 = 2.9547e-04\n",
      "Loss = 6.3048e-01, PNorm = 37.2693, GNorm = 1.2638, lr_0 = 2.8740e-04\n",
      "Loss = 5.8145e-01, PNorm = 37.2860, GNorm = 1.9738, lr_0 = 2.7954e-04\n",
      "Loss = 5.6666e-01, PNorm = 37.3029, GNorm = 1.7337, lr_0 = 2.7190e-04\n",
      "Loss = 4.8514e-01, PNorm = 37.3170, GNorm = 1.6250, lr_0 = 2.6447e-04\n",
      "Loss = 4.6812e-01, PNorm = 37.3300, GNorm = 1.1264, lr_0 = 2.5725e-04\n",
      "Loss = 5.5258e-01, PNorm = 37.3431, GNorm = 1.3078, lr_0 = 2.5022e-04\n",
      "Loss = 5.5739e-01, PNorm = 37.3552, GNorm = 2.6555, lr_0 = 2.4338e-04\n",
      "Loss = 6.1052e-01, PNorm = 37.3693, GNorm = 1.3377, lr_0 = 2.3673e-04\n",
      "Loss = 5.9988e-01, PNorm = 37.3811, GNorm = 1.2468, lr_0 = 2.3026e-04\n",
      "Loss = 5.9872e-01, PNorm = 37.3920, GNorm = 1.1765, lr_0 = 2.2397e-04\n",
      "Loss = 5.8368e-01, PNorm = 37.4032, GNorm = 1.1900, lr_0 = 2.1784e-04\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [01:15<04:59, 18.73s/it]Epoch 4\n",
      "Loss = 6.3806e-01, PNorm = 37.4181, GNorm = 3.2253, lr_0 = 2.1130e-04\n",
      "Loss = 4.1708e-01, PNorm = 37.4306, GNorm = 2.2882, lr_0 = 2.0553e-04\n",
      "Loss = 5.7537e-01, PNorm = 37.4414, GNorm = 1.7248, lr_0 = 1.9991e-04\n",
      "Loss = 4.9313e-01, PNorm = 37.4519, GNorm = 1.0916, lr_0 = 1.9445e-04\n",
      "Loss = 5.8585e-01, PNorm = 37.4647, GNorm = 1.1214, lr_0 = 1.8914e-04\n",
      "Loss = 5.1111e-01, PNorm = 37.4721, GNorm = 2.1212, lr_0 = 1.8397e-04\n",
      "Loss = 5.4145e-01, PNorm = 37.4818, GNorm = 1.1466, lr_0 = 1.7894e-04\n",
      "Loss = 5.5542e-01, PNorm = 37.4939, GNorm = 1.7591, lr_0 = 1.7405e-04\n",
      "Loss = 5.0475e-01, PNorm = 37.5036, GNorm = 1.3955, lr_0 = 1.6929e-04\n",
      "Loss = 5.8824e-01, PNorm = 37.5118, GNorm = 1.4590, lr_0 = 1.6467e-04\n",
      "Loss = 5.7002e-01, PNorm = 37.5184, GNorm = 1.3410, lr_0 = 1.6017e-04\n",
      "Loss = 5.1244e-01, PNorm = 37.5259, GNorm = 2.3103, lr_0 = 1.5579e-04\n",
      "Loss = 5.4522e-01, PNorm = 37.5329, GNorm = 1.4722, lr_0 = 1.5153e-04\n",
      "Loss = 5.9281e-01, PNorm = 37.5419, GNorm = 1.4599, lr_0 = 1.4739e-04\n",
      "Loss = 5.4411e-01, PNorm = 37.5485, GNorm = 1.7568, lr_0 = 1.4336e-04\n",
      "Loss = 5.2326e-01, PNorm = 37.5551, GNorm = 0.9924, lr_0 = 1.3945e-04\n",
      "Loss = 5.1613e-01, PNorm = 37.5616, GNorm = 1.9518, lr_0 = 1.3563e-04\n",
      "Loss = 5.1767e-01, PNorm = 37.5674, GNorm = 1.1936, lr_0 = 1.3193e-04\n",
      "Loss = 5.5008e-01, PNorm = 37.5737, GNorm = 1.3610, lr_0 = 1.2832e-04\n",
      "Loss = 5.5282e-01, PNorm = 37.5785, GNorm = 1.4401, lr_0 = 1.2482e-04\n",
      "Loss = 5.0639e-01, PNorm = 37.5840, GNorm = 1.4690, lr_0 = 1.2140e-04\n",
      "Loss = 5.4921e-01, PNorm = 37.5914, GNorm = 1.6986, lr_0 = 1.1809e-04\n",
      "Loss = 4.7111e-01, PNorm = 37.5970, GNorm = 1.4031, lr_0 = 1.1486e-04\n",
      "Loss = 5.1158e-01, PNorm = 37.6006, GNorm = 2.3970, lr_0 = 1.1172e-04\n",
      "Loss = 5.5723e-01, PNorm = 37.6051, GNorm = 2.1676, lr_0 = 1.0867e-04\n",
      "Loss = 5.4937e-01, PNorm = 37.6090, GNorm = 2.0849, lr_0 = 1.0570e-04\n",
      "Loss = 5.6854e-01, PNorm = 37.6140, GNorm = 3.3369, lr_0 = 1.0281e-04\n",
      "Loss = 5.2927e-01, PNorm = 37.6200, GNorm = 1.6841, lr_0 = 1.0000e-04\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [01:33<04:36, 18.44s/it]Epoch 5\n",
      "Loss = 4.6892e-01, PNorm = 37.6243, GNorm = 2.0557, lr_0 = 1.0000e-04\n",
      "Loss = 5.5355e-01, PNorm = 37.6292, GNorm = 1.6554, lr_0 = 1.0000e-04\n",
      "Loss = 5.7206e-01, PNorm = 37.6345, GNorm = 3.4749, lr_0 = 1.0000e-04\n",
      "Loss = 5.4266e-01, PNorm = 37.6398, GNorm = 1.6434, lr_0 = 1.0000e-04\n",
      "Loss = 5.5539e-01, PNorm = 37.6456, GNorm = 1.5232, lr_0 = 1.0000e-04\n",
      "Loss = 4.9569e-01, PNorm = 37.6504, GNorm = 1.6216, lr_0 = 1.0000e-04\n",
      "Loss = 4.8259e-01, PNorm = 37.6540, GNorm = 1.5564, lr_0 = 1.0000e-04\n",
      "Loss = 5.2410e-01, PNorm = 37.6572, GNorm = 2.0806, lr_0 = 1.0000e-04\n",
      "Loss = 5.6652e-01, PNorm = 37.6604, GNorm = 1.1797, lr_0 = 1.0000e-04\n",
      "Loss = 5.1838e-01, PNorm = 37.6650, GNorm = 1.9202, lr_0 = 1.0000e-04\n",
      "Loss = 5.5471e-01, PNorm = 37.6715, GNorm = 1.6455, lr_0 = 1.0000e-04\n",
      "Loss = 4.9207e-01, PNorm = 37.6766, GNorm = 1.3245, lr_0 = 1.0000e-04\n",
      "Loss = 4.5319e-01, PNorm = 37.6810, GNorm = 1.1527, lr_0 = 1.0000e-04\n",
      "Loss = 5.2212e-01, PNorm = 37.6872, GNorm = 1.2713, lr_0 = 1.0000e-04\n",
      "Loss = 4.8881e-01, PNorm = 37.6919, GNorm = 3.6197, lr_0 = 1.0000e-04\n",
      "Loss = 5.0438e-01, PNorm = 37.6960, GNorm = 1.5811, lr_0 = 1.0000e-04\n",
      "Loss = 5.1868e-01, PNorm = 37.7005, GNorm = 1.0925, lr_0 = 1.0000e-04\n",
      "Loss = 4.9194e-01, PNorm = 37.7052, GNorm = 1.5511, lr_0 = 1.0000e-04\n",
      "Loss = 5.2809e-01, PNorm = 37.7095, GNorm = 1.8259, lr_0 = 1.0000e-04\n",
      "Loss = 5.4345e-01, PNorm = 37.7125, GNorm = 1.6407, lr_0 = 1.0000e-04\n",
      "Loss = 5.1866e-01, PNorm = 37.7168, GNorm = 1.4622, lr_0 = 1.0000e-04\n",
      "Loss = 5.3251e-01, PNorm = 37.7229, GNorm = 1.3842, lr_0 = 1.0000e-04\n",
      "Loss = 5.5582e-01, PNorm = 37.7288, GNorm = 1.1669, lr_0 = 1.0000e-04\n",
      "Loss = 4.9674e-01, PNorm = 37.7344, GNorm = 1.8418, lr_0 = 1.0000e-04\n",
      "Loss = 4.8189e-01, PNorm = 37.7394, GNorm = 1.3514, lr_0 = 1.0000e-04\n",
      "Loss = 5.0842e-01, PNorm = 37.7443, GNorm = 2.3657, lr_0 = 1.0000e-04\n",
      "Loss = 4.9353e-01, PNorm = 37.7472, GNorm = 1.2964, lr_0 = 1.0000e-04\n",
      "Loss = 5.0900e-01, PNorm = 37.7506, GNorm = 1.9385, lr_0 = 1.0000e-04\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [01:51<04:18, 18.48s/it]Epoch 6\n",
      "Loss = 4.9500e-01, PNorm = 37.7553, GNorm = 0.9831, lr_0 = 1.0000e-04\n",
      "Loss = 5.2819e-01, PNorm = 37.7594, GNorm = 1.2638, lr_0 = 1.0000e-04\n",
      "Loss = 5.1546e-01, PNorm = 37.7639, GNorm = 1.2623, lr_0 = 1.0000e-04\n",
      "Loss = 4.8049e-01, PNorm = 37.7686, GNorm = 1.3346, lr_0 = 1.0000e-04\n",
      "Loss = 4.7337e-01, PNorm = 37.7731, GNorm = 2.9451, lr_0 = 1.0000e-04\n",
      "Loss = 5.0609e-01, PNorm = 37.7776, GNorm = 2.1219, lr_0 = 1.0000e-04\n",
      "Loss = 5.1735e-01, PNorm = 37.7825, GNorm = 2.1674, lr_0 = 1.0000e-04\n",
      "Loss = 4.8246e-01, PNorm = 37.7872, GNorm = 0.9403, lr_0 = 1.0000e-04\n",
      "Loss = 4.4017e-01, PNorm = 37.7910, GNorm = 2.5506, lr_0 = 1.0000e-04\n",
      "Loss = 5.5704e-01, PNorm = 37.7960, GNorm = 2.4324, lr_0 = 1.0000e-04\n",
      "Loss = 5.4968e-01, PNorm = 37.8010, GNorm = 1.1831, lr_0 = 1.0000e-04\n",
      "Loss = 4.1982e-01, PNorm = 37.8063, GNorm = 1.8117, lr_0 = 1.0000e-04\n",
      "Loss = 5.4577e-01, PNorm = 37.8110, GNorm = 1.1508, lr_0 = 1.0000e-04\n",
      "Loss = 4.9603e-01, PNorm = 37.8165, GNorm = 1.8917, lr_0 = 1.0000e-04\n",
      "Loss = 6.0596e-01, PNorm = 37.8212, GNorm = 2.0588, lr_0 = 1.0000e-04\n",
      "Loss = 4.8907e-01, PNorm = 37.8259, GNorm = 1.3709, lr_0 = 1.0000e-04\n",
      "Loss = 4.9763e-01, PNorm = 37.8300, GNorm = 1.2973, lr_0 = 1.0000e-04\n",
      "Loss = 5.4599e-01, PNorm = 37.8346, GNorm = 2.3325, lr_0 = 1.0000e-04\n",
      "Loss = 5.0053e-01, PNorm = 37.8392, GNorm = 1.3383, lr_0 = 1.0000e-04\n",
      "Loss = 5.1019e-01, PNorm = 37.8428, GNorm = 1.1592, lr_0 = 1.0000e-04\n",
      "Loss = 5.4131e-01, PNorm = 37.8463, GNorm = 1.4778, lr_0 = 1.0000e-04\n",
      "Loss = 4.7796e-01, PNorm = 37.8515, GNorm = 1.6195, lr_0 = 1.0000e-04\n",
      "Loss = 4.4173e-01, PNorm = 37.8563, GNorm = 2.4652, lr_0 = 1.0000e-04\n",
      "Loss = 4.9631e-01, PNorm = 37.8620, GNorm = 1.2643, lr_0 = 1.0000e-04\n",
      "Loss = 4.9916e-01, PNorm = 37.8665, GNorm = 2.0435, lr_0 = 1.0000e-04\n",
      "Loss = 4.8386e-01, PNorm = 37.8713, GNorm = 1.6990, lr_0 = 1.0000e-04\n",
      "Loss = 5.1475e-01, PNorm = 37.8751, GNorm = 1.7090, lr_0 = 1.0000e-04\n",
      "Loss = 5.0459e-01, PNorm = 37.8796, GNorm = 2.8276, lr_0 = 1.0000e-04\n",
      "Loss = 5.6291e-01, PNorm = 37.8799, GNorm = 6.4315, lr_0 = 1.0000e-04\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [02:10<04:02, 18.66s/it]Epoch 7\n",
      "Loss = 5.3357e-01, PNorm = 37.8838, GNorm = 0.9981, lr_0 = 1.0000e-04\n",
      "Loss = 5.0461e-01, PNorm = 37.8903, GNorm = 2.2744, lr_0 = 1.0000e-04\n",
      "Loss = 4.8381e-01, PNorm = 37.8955, GNorm = 1.8201, lr_0 = 1.0000e-04\n",
      "Loss = 4.9484e-01, PNorm = 37.9015, GNorm = 1.6369, lr_0 = 1.0000e-04\n",
      "Loss = 4.8250e-01, PNorm = 37.9065, GNorm = 2.2900, lr_0 = 1.0000e-04\n",
      "Loss = 5.2181e-01, PNorm = 37.9114, GNorm = 2.2647, lr_0 = 1.0000e-04\n",
      "Loss = 4.9141e-01, PNorm = 37.9150, GNorm = 1.6636, lr_0 = 1.0000e-04\n",
      "Loss = 5.2257e-01, PNorm = 37.9186, GNorm = 1.5665, lr_0 = 1.0000e-04\n",
      "Loss = 4.8186e-01, PNorm = 37.9212, GNorm = 2.1729, lr_0 = 1.0000e-04\n",
      "Loss = 4.7409e-01, PNorm = 37.9256, GNorm = 1.7660, lr_0 = 1.0000e-04\n",
      "Loss = 5.6693e-01, PNorm = 37.9298, GNorm = 1.4603, lr_0 = 1.0000e-04\n",
      "Loss = 4.5930e-01, PNorm = 37.9340, GNorm = 1.5497, lr_0 = 1.0000e-04\n",
      "Loss = 5.3103e-01, PNorm = 37.9379, GNorm = 2.1196, lr_0 = 1.0000e-04\n",
      "Loss = 4.8891e-01, PNorm = 37.9423, GNorm = 2.5112, lr_0 = 1.0000e-04\n",
      "Loss = 4.6178e-01, PNorm = 37.9472, GNorm = 1.0966, lr_0 = 1.0000e-04\n",
      "Loss = 5.4171e-01, PNorm = 37.9513, GNorm = 1.8067, lr_0 = 1.0000e-04\n",
      "Loss = 4.8530e-01, PNorm = 37.9551, GNorm = 1.7997, lr_0 = 1.0000e-04\n",
      "Loss = 4.7027e-01, PNorm = 37.9600, GNorm = 1.7688, lr_0 = 1.0000e-04\n",
      "Loss = 4.6223e-01, PNorm = 37.9646, GNorm = 2.5287, lr_0 = 1.0000e-04\n",
      "Loss = 5.0882e-01, PNorm = 37.9699, GNorm = 1.8468, lr_0 = 1.0000e-04\n",
      "Loss = 5.2505e-01, PNorm = 37.9744, GNorm = 1.4135, lr_0 = 1.0000e-04\n",
      "Loss = 4.7995e-01, PNorm = 37.9787, GNorm = 2.7089, lr_0 = 1.0000e-04\n",
      "Loss = 4.3369e-01, PNorm = 37.9828, GNorm = 1.6695, lr_0 = 1.0000e-04\n",
      "Loss = 4.4319e-01, PNorm = 37.9858, GNorm = 2.2014, lr_0 = 1.0000e-04\n",
      "Loss = 5.1851e-01, PNorm = 37.9889, GNorm = 1.8982, lr_0 = 1.0000e-04\n",
      "Loss = 4.9088e-01, PNorm = 37.9934, GNorm = 1.3895, lr_0 = 1.0000e-04\n",
      "Loss = 4.7869e-01, PNorm = 37.9987, GNorm = 1.2922, lr_0 = 1.0000e-04\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [02:28<03:41, 18.47s/it]Epoch 8\n",
      "Loss = 5.0577e-01, PNorm = 38.0052, GNorm = 1.6378, lr_0 = 1.0000e-04\n",
      "Loss = 4.8428e-01, PNorm = 38.0115, GNorm = 1.7268, lr_0 = 1.0000e-04\n",
      "Loss = 4.8389e-01, PNorm = 38.0165, GNorm = 2.1595, lr_0 = 1.0000e-04\n",
      "Loss = 4.9712e-01, PNorm = 38.0200, GNorm = 2.5500, lr_0 = 1.0000e-04\n",
      "Loss = 4.8174e-01, PNorm = 38.0253, GNorm = 1.8441, lr_0 = 1.0000e-04\n",
      "Loss = 5.0551e-01, PNorm = 38.0321, GNorm = 1.7690, lr_0 = 1.0000e-04\n",
      "Loss = 4.8343e-01, PNorm = 38.0372, GNorm = 1.8970, lr_0 = 1.0000e-04\n",
      "Loss = 4.6061e-01, PNorm = 38.0408, GNorm = 1.6043, lr_0 = 1.0000e-04\n",
      "Loss = 4.9438e-01, PNorm = 38.0439, GNorm = 1.5648, lr_0 = 1.0000e-04\n",
      "Loss = 4.3073e-01, PNorm = 38.0479, GNorm = 1.4948, lr_0 = 1.0000e-04\n",
      "Loss = 5.3742e-01, PNorm = 38.0510, GNorm = 2.5694, lr_0 = 1.0000e-04\n",
      "Loss = 4.3915e-01, PNorm = 38.0547, GNorm = 1.5085, lr_0 = 1.0000e-04\n",
      "Loss = 5.0752e-01, PNorm = 38.0582, GNorm = 1.2726, lr_0 = 1.0000e-04\n",
      "Loss = 4.8325e-01, PNorm = 38.0628, GNorm = 2.8703, lr_0 = 1.0000e-04\n",
      "Loss = 5.0232e-01, PNorm = 38.0672, GNorm = 2.4805, lr_0 = 1.0000e-04\n",
      "Loss = 4.2709e-01, PNorm = 38.0724, GNorm = 1.7005, lr_0 = 1.0000e-04\n",
      "Loss = 4.6029e-01, PNorm = 38.0779, GNorm = 1.0245, lr_0 = 1.0000e-04\n",
      "Loss = 4.9369e-01, PNorm = 38.0824, GNorm = 1.3674, lr_0 = 1.0000e-04\n",
      "Loss = 4.4118e-01, PNorm = 38.0871, GNorm = 1.2931, lr_0 = 1.0000e-04\n",
      "Loss = 5.2642e-01, PNorm = 38.0914, GNorm = 1.7367, lr_0 = 1.0000e-04\n",
      "Loss = 4.5627e-01, PNorm = 38.0945, GNorm = 1.7307, lr_0 = 1.0000e-04\n",
      "Loss = 5.2211e-01, PNorm = 38.0990, GNorm = 1.1267, lr_0 = 1.0000e-04\n",
      "Loss = 4.9078e-01, PNorm = 38.1044, GNorm = 1.5054, lr_0 = 1.0000e-04\n",
      "Loss = 4.4516e-01, PNorm = 38.1090, GNorm = 2.6023, lr_0 = 1.0000e-04\n",
      "Loss = 4.6661e-01, PNorm = 38.1130, GNorm = 4.0234, lr_0 = 1.0000e-04\n",
      "Loss = 5.0687e-01, PNorm = 38.1167, GNorm = 1.7778, lr_0 = 1.0000e-04\n",
      "Loss = 5.3511e-01, PNorm = 38.1207, GNorm = 3.0483, lr_0 = 1.0000e-04\n",
      "Loss = 5.0059e-01, PNorm = 38.1239, GNorm = 1.4838, lr_0 = 1.0000e-04\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [02:46<03:20, 18.22s/it]Epoch 9\n",
      "Loss = 4.4479e-01, PNorm = 38.1279, GNorm = 1.5516, lr_0 = 1.0000e-04\n",
      "Loss = 5.1923e-01, PNorm = 38.1334, GNorm = 2.5774, lr_0 = 1.0000e-04\n",
      "Loss = 4.5753e-01, PNorm = 38.1388, GNorm = 1.2318, lr_0 = 1.0000e-04\n",
      "Loss = 4.9806e-01, PNorm = 38.1441, GNorm = 1.7440, lr_0 = 1.0000e-04\n",
      "Loss = 4.9163e-01, PNorm = 38.1480, GNorm = 2.6786, lr_0 = 1.0000e-04\n",
      "Loss = 4.8810e-01, PNorm = 38.1517, GNorm = 2.9203, lr_0 = 1.0000e-04\n",
      "Loss = 5.1139e-01, PNorm = 38.1559, GNorm = 1.7513, lr_0 = 1.0000e-04\n",
      "Loss = 4.5199e-01, PNorm = 38.1599, GNorm = 1.1824, lr_0 = 1.0000e-04\n",
      "Loss = 4.7820e-01, PNorm = 38.1649, GNorm = 1.6134, lr_0 = 1.0000e-04\n",
      "Loss = 4.7331e-01, PNorm = 38.1685, GNorm = 1.8959, lr_0 = 1.0000e-04\n",
      "Loss = 4.4725e-01, PNorm = 38.1729, GNorm = 1.3753, lr_0 = 1.0000e-04\n",
      "Loss = 4.4472e-01, PNorm = 38.1763, GNorm = 1.6780, lr_0 = 1.0000e-04\n",
      "Loss = 4.6134e-01, PNorm = 38.1801, GNorm = 1.1948, lr_0 = 1.0000e-04\n",
      "Loss = 4.5221e-01, PNorm = 38.1845, GNorm = 2.9828, lr_0 = 1.0000e-04\n",
      "Loss = 4.4234e-01, PNorm = 38.1890, GNorm = 2.1561, lr_0 = 1.0000e-04\n",
      "Loss = 5.1087e-01, PNorm = 38.1929, GNorm = 2.4711, lr_0 = 1.0000e-04\n",
      "Loss = 5.0277e-01, PNorm = 38.1969, GNorm = 2.4672, lr_0 = 1.0000e-04\n",
      "Loss = 4.9193e-01, PNorm = 38.2004, GNorm = 1.7475, lr_0 = 1.0000e-04\n",
      "Loss = 4.9537e-01, PNorm = 38.2042, GNorm = 2.0984, lr_0 = 1.0000e-04\n",
      "Loss = 4.4343e-01, PNorm = 38.2078, GNorm = 1.7734, lr_0 = 1.0000e-04\n",
      "Loss = 4.7630e-01, PNorm = 38.2113, GNorm = 3.1765, lr_0 = 1.0000e-04\n",
      "Loss = 4.7818e-01, PNorm = 38.2165, GNorm = 2.3406, lr_0 = 1.0000e-04\n",
      "Loss = 4.3548e-01, PNorm = 38.2215, GNorm = 1.7141, lr_0 = 1.0000e-04\n",
      "Loss = 4.4047e-01, PNorm = 38.2264, GNorm = 1.7539, lr_0 = 1.0000e-04\n",
      "Loss = 4.8288e-01, PNorm = 38.2307, GNorm = 1.6982, lr_0 = 1.0000e-04\n",
      "Loss = 5.4160e-01, PNorm = 38.2358, GNorm = 2.3056, lr_0 = 1.0000e-04\n",
      "Loss = 4.6332e-01, PNorm = 38.2400, GNorm = 2.0066, lr_0 = 1.0000e-04\n",
      "Loss = 4.6666e-01, PNorm = 38.2450, GNorm = 1.7990, lr_0 = 1.0000e-04\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [03:03<02:58, 17.82s/it]Epoch 10\n",
      "Loss = 5.0396e-01, PNorm = 38.2496, GNorm = 3.1708, lr_0 = 1.0000e-04\n",
      "Loss = 4.6752e-01, PNorm = 38.2536, GNorm = 2.2083, lr_0 = 1.0000e-04\n",
      "Loss = 4.9649e-01, PNorm = 38.2585, GNorm = 1.7628, lr_0 = 1.0000e-04\n",
      "Loss = 4.3955e-01, PNorm = 38.2636, GNorm = 2.2631, lr_0 = 1.0000e-04\n",
      "Loss = 4.2390e-01, PNorm = 38.2674, GNorm = 1.1980, lr_0 = 1.0000e-04\n",
      "Loss = 4.7462e-01, PNorm = 38.2714, GNorm = 1.5250, lr_0 = 1.0000e-04\n",
      "Loss = 4.5528e-01, PNorm = 38.2765, GNorm = 1.7278, lr_0 = 1.0000e-04\n",
      "Loss = 4.7786e-01, PNorm = 38.2821, GNorm = 1.7764, lr_0 = 1.0000e-04\n",
      "Loss = 4.6861e-01, PNorm = 38.2868, GNorm = 4.2535, lr_0 = 1.0000e-04\n",
      "Loss = 4.4768e-01, PNorm = 38.2906, GNorm = 1.8037, lr_0 = 1.0000e-04\n",
      "Loss = 4.7688e-01, PNorm = 38.2941, GNorm = 1.9599, lr_0 = 1.0000e-04\n",
      "Loss = 4.5947e-01, PNorm = 38.2970, GNorm = 1.6040, lr_0 = 1.0000e-04\n",
      "Loss = 4.8883e-01, PNorm = 38.3002, GNorm = 2.8050, lr_0 = 1.0000e-04\n",
      "Loss = 4.4539e-01, PNorm = 38.3046, GNorm = 1.7664, lr_0 = 1.0000e-04\n",
      "Loss = 4.0577e-01, PNorm = 38.3086, GNorm = 1.2556, lr_0 = 1.0000e-04\n",
      "Loss = 4.7516e-01, PNorm = 38.3133, GNorm = 1.7996, lr_0 = 1.0000e-04\n",
      "Loss = 4.9954e-01, PNorm = 38.3176, GNorm = 1.9222, lr_0 = 1.0000e-04\n",
      "Loss = 4.7968e-01, PNorm = 38.3216, GNorm = 2.9450, lr_0 = 1.0000e-04\n",
      "Loss = 4.2563e-01, PNorm = 38.3246, GNorm = 1.4418, lr_0 = 1.0000e-04\n",
      "Loss = 4.6466e-01, PNorm = 38.3280, GNorm = 1.8551, lr_0 = 1.0000e-04\n",
      "Loss = 4.9713e-01, PNorm = 38.3328, GNorm = 1.2557, lr_0 = 1.0000e-04\n",
      "Loss = 4.7564e-01, PNorm = 38.3369, GNorm = 1.9997, lr_0 = 1.0000e-04\n",
      "Loss = 4.8930e-01, PNorm = 38.3415, GNorm = 1.4134, lr_0 = 1.0000e-04\n",
      "Loss = 4.4127e-01, PNorm = 38.3456, GNorm = 2.4341, lr_0 = 1.0000e-04\n",
      "Loss = 4.4486e-01, PNorm = 38.3482, GNorm = 1.2868, lr_0 = 1.0000e-04\n",
      "Loss = 4.2533e-01, PNorm = 38.3516, GNorm = 2.1618, lr_0 = 1.0000e-04\n",
      "Loss = 4.7868e-01, PNorm = 38.3562, GNorm = 1.6746, lr_0 = 1.0000e-04\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [03:19<02:36, 17.38s/it]Epoch 11\n",
      "Loss = 4.0318e-01, PNorm = 38.3606, GNorm = 2.0413, lr_0 = 1.0000e-04\n",
      "Loss = 4.6054e-01, PNorm = 38.3641, GNorm = 2.8709, lr_0 = 1.0000e-04\n",
      "Loss = 4.6379e-01, PNorm = 38.3690, GNorm = 2.5980, lr_0 = 1.0000e-04\n",
      "Loss = 4.8578e-01, PNorm = 38.3741, GNorm = 3.5964, lr_0 = 1.0000e-04\n",
      "Loss = 4.4758e-01, PNorm = 38.3779, GNorm = 1.8092, lr_0 = 1.0000e-04\n",
      "Loss = 3.9480e-01, PNorm = 38.3816, GNorm = 1.9438, lr_0 = 1.0000e-04\n",
      "Loss = 4.3720e-01, PNorm = 38.3857, GNorm = 3.6234, lr_0 = 1.0000e-04\n",
      "Loss = 3.4203e-01, PNorm = 38.3898, GNorm = 2.0008, lr_0 = 1.0000e-04\n",
      "Loss = 4.5742e-01, PNorm = 38.3940, GNorm = 5.4786, lr_0 = 1.0000e-04\n",
      "Loss = 4.5588e-01, PNorm = 38.3984, GNorm = 1.8536, lr_0 = 1.0000e-04\n",
      "Loss = 4.5194e-01, PNorm = 38.4025, GNorm = 1.3046, lr_0 = 1.0000e-04\n",
      "Loss = 4.5710e-01, PNorm = 38.4062, GNorm = 1.6184, lr_0 = 1.0000e-04\n",
      "Loss = 4.8213e-01, PNorm = 38.4099, GNorm = 1.7019, lr_0 = 1.0000e-04\n",
      "Loss = 4.6384e-01, PNorm = 38.4143, GNorm = 1.6884, lr_0 = 1.0000e-04\n",
      "Loss = 4.6894e-01, PNorm = 38.4186, GNorm = 2.3669, lr_0 = 1.0000e-04\n",
      "Loss = 4.1892e-01, PNorm = 38.4226, GNorm = 2.0011, lr_0 = 1.0000e-04\n",
      "Loss = 4.0965e-01, PNorm = 38.4268, GNorm = 2.4816, lr_0 = 1.0000e-04\n",
      "Loss = 5.0182e-01, PNorm = 38.4310, GNorm = 1.6759, lr_0 = 1.0000e-04\n",
      "Loss = 4.7399e-01, PNorm = 38.4342, GNorm = 1.4827, lr_0 = 1.0000e-04\n",
      "Loss = 4.7767e-01, PNorm = 38.4378, GNorm = 2.3321, lr_0 = 1.0000e-04\n",
      "Loss = 4.9919e-01, PNorm = 38.4435, GNorm = 3.9129, lr_0 = 1.0000e-04\n",
      "Loss = 4.8134e-01, PNorm = 38.4492, GNorm = 3.1708, lr_0 = 1.0000e-04\n",
      "Loss = 4.4106e-01, PNorm = 38.4542, GNorm = 4.0935, lr_0 = 1.0000e-04\n",
      "Loss = 4.5370e-01, PNorm = 38.4588, GNorm = 2.7320, lr_0 = 1.0000e-04\n",
      "Loss = 3.9317e-01, PNorm = 38.4630, GNorm = 2.1263, lr_0 = 1.0000e-04\n",
      "Loss = 4.7791e-01, PNorm = 38.4671, GNorm = 2.2774, lr_0 = 1.0000e-04\n",
      "Loss = 4.4930e-01, PNorm = 38.4706, GNorm = 3.5438, lr_0 = 1.0000e-04\n",
      "Loss = 5.1055e-01, PNorm = 38.4736, GNorm = 2.6249, lr_0 = 1.0000e-04\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [03:40<02:27, 18.38s/it]Epoch 12\n",
      "Loss = 4.3805e-01, PNorm = 38.4764, GNorm = 4.0680, lr_0 = 1.0000e-04\n",
      "Loss = 4.4009e-01, PNorm = 38.4800, GNorm = 1.5458, lr_0 = 1.0000e-04\n",
      "Loss = 4.0494e-01, PNorm = 38.4845, GNorm = 3.9586, lr_0 = 1.0000e-04\n",
      "Loss = 4.8491e-01, PNorm = 38.4884, GNorm = 2.7248, lr_0 = 1.0000e-04\n",
      "Loss = 4.2002e-01, PNorm = 38.4926, GNorm = 2.0397, lr_0 = 1.0000e-04\n",
      "Loss = 4.5405e-01, PNorm = 38.4974, GNorm = 1.8907, lr_0 = 1.0000e-04\n",
      "Loss = 4.4493e-01, PNorm = 38.5017, GNorm = 1.5108, lr_0 = 1.0000e-04\n",
      "Loss = 4.4889e-01, PNorm = 38.5058, GNorm = 2.5690, lr_0 = 1.0000e-04\n",
      "Loss = 4.5557e-01, PNorm = 38.5104, GNorm = 1.9655, lr_0 = 1.0000e-04\n",
      "Loss = 4.7008e-01, PNorm = 38.5144, GNorm = 2.5758, lr_0 = 1.0000e-04\n",
      "Loss = 4.7635e-01, PNorm = 38.5187, GNorm = 2.1082, lr_0 = 1.0000e-04\n",
      "Loss = 4.9943e-01, PNorm = 38.5230, GNorm = 1.7032, lr_0 = 1.0000e-04\n",
      "Loss = 4.3137e-01, PNorm = 38.5267, GNorm = 1.7679, lr_0 = 1.0000e-04\n",
      "Loss = 4.8617e-01, PNorm = 38.5300, GNorm = 3.1683, lr_0 = 1.0000e-04\n",
      "Loss = 4.4307e-01, PNorm = 38.5331, GNorm = 1.8238, lr_0 = 1.0000e-04\n",
      "Loss = 4.0967e-01, PNorm = 38.5372, GNorm = 2.8867, lr_0 = 1.0000e-04\n",
      "Loss = 3.9449e-01, PNorm = 38.5421, GNorm = 2.4583, lr_0 = 1.0000e-04\n",
      "Loss = 3.8889e-01, PNorm = 38.5455, GNorm = 2.6343, lr_0 = 1.0000e-04\n",
      "Loss = 4.1921e-01, PNorm = 38.5497, GNorm = 1.9829, lr_0 = 1.0000e-04\n",
      "Loss = 4.4932e-01, PNorm = 38.5537, GNorm = 2.2273, lr_0 = 1.0000e-04\n",
      "Loss = 4.7785e-01, PNorm = 38.5571, GNorm = 1.3105, lr_0 = 1.0000e-04\n",
      "Loss = 4.7745e-01, PNorm = 38.5604, GNorm = 1.4352, lr_0 = 1.0000e-04\n",
      "Loss = 4.5902e-01, PNorm = 38.5648, GNorm = 3.7546, lr_0 = 1.0000e-04\n",
      "Loss = 4.2716e-01, PNorm = 38.5706, GNorm = 2.1169, lr_0 = 1.0000e-04\n",
      "Loss = 4.2872e-01, PNorm = 38.5752, GNorm = 2.5467, lr_0 = 1.0000e-04\n",
      "Loss = 4.8707e-01, PNorm = 38.5780, GNorm = 3.1600, lr_0 = 1.0000e-04\n",
      "Loss = 4.9082e-01, PNorm = 38.5815, GNorm = 3.0083, lr_0 = 1.0000e-04\n",
      "Loss = 3.9024e-01, PNorm = 38.5848, GNorm = 1.6983, lr_0 = 1.0000e-04\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [03:58<02:07, 18.17s/it]Epoch 13\n",
      "Loss = 4.2480e-01, PNorm = 38.5891, GNorm = 2.9718, lr_0 = 1.0000e-04\n",
      "Loss = 4.0200e-01, PNorm = 38.5928, GNorm = 3.4701, lr_0 = 1.0000e-04\n",
      "Loss = 4.1483e-01, PNorm = 38.5967, GNorm = 1.0103, lr_0 = 1.0000e-04\n",
      "Loss = 4.2197e-01, PNorm = 38.6010, GNorm = 1.7051, lr_0 = 1.0000e-04\n",
      "Loss = 4.6526e-01, PNorm = 38.6057, GNorm = 1.4205, lr_0 = 1.0000e-04\n",
      "Loss = 4.5816e-01, PNorm = 38.6101, GNorm = 2.3047, lr_0 = 1.0000e-04\n",
      "Loss = 4.0054e-01, PNorm = 38.6142, GNorm = 2.5427, lr_0 = 1.0000e-04\n",
      "Loss = 4.6332e-01, PNorm = 38.6175, GNorm = 1.9042, lr_0 = 1.0000e-04\n",
      "Loss = 4.2931e-01, PNorm = 38.6212, GNorm = 1.7532, lr_0 = 1.0000e-04\n",
      "Loss = 4.2045e-01, PNorm = 38.6255, GNorm = 1.2752, lr_0 = 1.0000e-04\n",
      "Loss = 3.9844e-01, PNorm = 38.6300, GNorm = 2.3328, lr_0 = 1.0000e-04\n",
      "Loss = 4.6816e-01, PNorm = 38.6339, GNorm = 3.6736, lr_0 = 1.0000e-04\n",
      "Loss = 4.7199e-01, PNorm = 38.6384, GNorm = 2.6689, lr_0 = 1.0000e-04\n",
      "Loss = 4.0164e-01, PNorm = 38.6420, GNorm = 1.8372, lr_0 = 1.0000e-04\n",
      "Loss = 4.7559e-01, PNorm = 38.6465, GNorm = 2.6133, lr_0 = 1.0000e-04\n",
      "Loss = 4.4061e-01, PNorm = 38.6505, GNorm = 2.0367, lr_0 = 1.0000e-04\n",
      "Loss = 4.4192e-01, PNorm = 38.6538, GNorm = 1.9474, lr_0 = 1.0000e-04\n",
      "Loss = 4.3099e-01, PNorm = 38.6577, GNorm = 2.2879, lr_0 = 1.0000e-04\n",
      "Loss = 3.7900e-01, PNorm = 38.6621, GNorm = 2.8012, lr_0 = 1.0000e-04\n",
      "Loss = 5.0905e-01, PNorm = 38.6656, GNorm = 3.2260, lr_0 = 1.0000e-04\n",
      "Loss = 4.1549e-01, PNorm = 38.6692, GNorm = 1.9472, lr_0 = 1.0000e-04\n",
      "Loss = 4.7323e-01, PNorm = 38.6726, GNorm = 2.7379, lr_0 = 1.0000e-04\n",
      "Loss = 4.4548e-01, PNorm = 38.6760, GNorm = 1.5667, lr_0 = 1.0000e-04\n",
      "Loss = 4.3288e-01, PNorm = 38.6793, GNorm = 2.3628, lr_0 = 1.0000e-04\n",
      "Loss = 4.5260e-01, PNorm = 38.6829, GNorm = 1.2841, lr_0 = 1.0000e-04\n",
      "Loss = 4.8337e-01, PNorm = 38.6871, GNorm = 2.4226, lr_0 = 1.0000e-04\n",
      "Loss = 4.3785e-01, PNorm = 38.6906, GNorm = 2.4381, lr_0 = 1.0000e-04\n",
      "Loss = 4.7019e-01, PNorm = 38.6932, GNorm = 5.3754, lr_0 = 1.0000e-04\n",
      "Loss = 1.3614e-01, PNorm = 38.6934, GNorm = 1.8794, lr_0 = 1.0000e-04\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [04:14<01:46, 17.73s/it]Epoch 14\n",
      "Loss = 4.4050e-01, PNorm = 38.6966, GNorm = 2.3385, lr_0 = 1.0000e-04\n",
      "Loss = 5.0205e-01, PNorm = 38.6997, GNorm = 3.5123, lr_0 = 1.0000e-04\n",
      "Loss = 3.8889e-01, PNorm = 38.7033, GNorm = 2.2801, lr_0 = 1.0000e-04\n",
      "Loss = 4.4564e-01, PNorm = 38.7071, GNorm = 1.6204, lr_0 = 1.0000e-04\n",
      "Loss = 4.0884e-01, PNorm = 38.7107, GNorm = 2.0139, lr_0 = 1.0000e-04\n",
      "Loss = 4.1637e-01, PNorm = 38.7147, GNorm = 2.3415, lr_0 = 1.0000e-04\n",
      "Loss = 4.2535e-01, PNorm = 38.7182, GNorm = 1.8564, lr_0 = 1.0000e-04\n",
      "Loss = 4.7779e-01, PNorm = 38.7231, GNorm = 3.1103, lr_0 = 1.0000e-04\n",
      "Loss = 4.4834e-01, PNorm = 38.7280, GNorm = 1.7407, lr_0 = 1.0000e-04\n",
      "Loss = 3.9644e-01, PNorm = 38.7325, GNorm = 2.8400, lr_0 = 1.0000e-04\n",
      "Loss = 3.9974e-01, PNorm = 38.7357, GNorm = 1.5507, lr_0 = 1.0000e-04\n",
      "Loss = 4.5550e-01, PNorm = 38.7389, GNorm = 1.7120, lr_0 = 1.0000e-04\n",
      "Loss = 4.1911e-01, PNorm = 38.7424, GNorm = 2.0985, lr_0 = 1.0000e-04\n",
      "Loss = 4.7819e-01, PNorm = 38.7460, GNorm = 2.5928, lr_0 = 1.0000e-04\n",
      "Loss = 4.7109e-01, PNorm = 38.7507, GNorm = 1.5746, lr_0 = 1.0000e-04\n",
      "Loss = 4.5427e-01, PNorm = 38.7550, GNorm = 1.6136, lr_0 = 1.0000e-04\n",
      "Loss = 4.2328e-01, PNorm = 38.7586, GNorm = 1.4030, lr_0 = 1.0000e-04\n",
      "Loss = 4.2400e-01, PNorm = 38.7614, GNorm = 1.5036, lr_0 = 1.0000e-04\n",
      "Loss = 4.1925e-01, PNorm = 38.7651, GNorm = 1.4930, lr_0 = 1.0000e-04\n",
      "Loss = 3.8366e-01, PNorm = 38.7693, GNorm = 3.3279, lr_0 = 1.0000e-04\n",
      "Loss = 4.7310e-01, PNorm = 38.7727, GNorm = 2.4275, lr_0 = 1.0000e-04\n",
      "Loss = 3.9296e-01, PNorm = 38.7752, GNorm = 1.2281, lr_0 = 1.0000e-04\n",
      "Loss = 4.5951e-01, PNorm = 38.7793, GNorm = 2.7427, lr_0 = 1.0000e-04\n",
      "Loss = 4.6705e-01, PNorm = 38.7836, GNorm = 1.8915, lr_0 = 1.0000e-04\n",
      "Loss = 3.7026e-01, PNorm = 38.7874, GNorm = 2.1085, lr_0 = 1.0000e-04\n",
      "Loss = 3.6374e-01, PNorm = 38.7915, GNorm = 2.3268, lr_0 = 1.0000e-04\n",
      "Loss = 3.8887e-01, PNorm = 38.7948, GNorm = 1.9917, lr_0 = 1.0000e-04\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [04:32<01:28, 17.63s/it]Epoch 15\n",
      "Loss = 5.0715e-01, PNorm = 38.7993, GNorm = 3.6011, lr_0 = 1.0000e-04\n",
      "Loss = 4.0616e-01, PNorm = 38.8035, GNorm = 1.6075, lr_0 = 1.0000e-04\n",
      "Loss = 3.6950e-01, PNorm = 38.8080, GNorm = 2.8795, lr_0 = 1.0000e-04\n",
      "Loss = 4.2229e-01, PNorm = 38.8120, GNorm = 1.8411, lr_0 = 1.0000e-04\n",
      "Loss = 4.5455e-01, PNorm = 38.8167, GNorm = 1.5564, lr_0 = 1.0000e-04\n",
      "Loss = 4.2221e-01, PNorm = 38.8209, GNorm = 3.7077, lr_0 = 1.0000e-04\n",
      "Loss = 4.6424e-01, PNorm = 38.8254, GNorm = 2.4845, lr_0 = 1.0000e-04\n",
      "Loss = 4.3259e-01, PNorm = 38.8292, GNorm = 1.6806, lr_0 = 1.0000e-04\n",
      "Loss = 4.2466e-01, PNorm = 38.8330, GNorm = 1.6275, lr_0 = 1.0000e-04\n",
      "Loss = 4.1733e-01, PNorm = 38.8366, GNorm = 1.8837, lr_0 = 1.0000e-04\n",
      "Loss = 4.1089e-01, PNorm = 38.8389, GNorm = 1.7149, lr_0 = 1.0000e-04\n",
      "Loss = 5.0813e-01, PNorm = 38.8422, GNorm = 1.7000, lr_0 = 1.0000e-04\n",
      "Loss = 3.7866e-01, PNorm = 38.8453, GNorm = 1.8058, lr_0 = 1.0000e-04\n",
      "Loss = 4.0273e-01, PNorm = 38.8496, GNorm = 1.7233, lr_0 = 1.0000e-04\n",
      "Loss = 4.2083e-01, PNorm = 38.8545, GNorm = 2.7289, lr_0 = 1.0000e-04\n",
      "Loss = 4.7530e-01, PNorm = 38.8585, GNorm = 3.3030, lr_0 = 1.0000e-04\n",
      "Loss = 4.4297e-01, PNorm = 38.8634, GNorm = 1.2105, lr_0 = 1.0000e-04\n",
      "Loss = 4.4964e-01, PNorm = 38.8669, GNorm = 1.4767, lr_0 = 1.0000e-04\n",
      "Loss = 4.2516e-01, PNorm = 38.8704, GNorm = 1.8433, lr_0 = 1.0000e-04\n",
      "Loss = 4.2700e-01, PNorm = 38.8732, GNorm = 1.9724, lr_0 = 1.0000e-04\n",
      "Loss = 3.6481e-01, PNorm = 38.8755, GNorm = 1.3578, lr_0 = 1.0000e-04\n",
      "Loss = 4.1526e-01, PNorm = 38.8794, GNorm = 1.7678, lr_0 = 1.0000e-04\n",
      "Loss = 3.8991e-01, PNorm = 38.8835, GNorm = 1.5440, lr_0 = 1.0000e-04\n",
      "Loss = 3.9229e-01, PNorm = 38.8875, GNorm = 1.6923, lr_0 = 1.0000e-04\n",
      "Loss = 4.1683e-01, PNorm = 38.8915, GNorm = 2.6933, lr_0 = 1.0000e-04\n",
      "Loss = 4.1073e-01, PNorm = 38.8951, GNorm = 2.2769, lr_0 = 1.0000e-04\n",
      "Loss = 3.8734e-01, PNorm = 38.8984, GNorm = 1.6531, lr_0 = 1.0000e-04\n",
      "Loss = 4.3138e-01, PNorm = 38.9009, GNorm = 1.5870, lr_0 = 1.0000e-04\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [04:49<01:09, 17.40s/it]Epoch 16\n",
      "Loss = 4.1344e-01, PNorm = 38.9041, GNorm = 1.2822, lr_0 = 1.0000e-04\n",
      "Loss = 4.1318e-01, PNorm = 38.9074, GNorm = 1.6137, lr_0 = 1.0000e-04\n",
      "Loss = 4.3990e-01, PNorm = 38.9112, GNorm = 1.5091, lr_0 = 1.0000e-04\n",
      "Loss = 3.8387e-01, PNorm = 38.9145, GNorm = 1.3653, lr_0 = 1.0000e-04\n",
      "Loss = 4.2679e-01, PNorm = 38.9180, GNorm = 2.0032, lr_0 = 1.0000e-04\n",
      "Loss = 3.7318e-01, PNorm = 38.9217, GNorm = 3.4655, lr_0 = 1.0000e-04\n",
      "Loss = 4.1200e-01, PNorm = 38.9254, GNorm = 3.1358, lr_0 = 1.0000e-04\n",
      "Loss = 3.8930e-01, PNorm = 38.9291, GNorm = 2.5272, lr_0 = 1.0000e-04\n",
      "Loss = 4.3391e-01, PNorm = 38.9324, GNorm = 2.4190, lr_0 = 1.0000e-04\n",
      "Loss = 4.7552e-01, PNorm = 38.9358, GNorm = 2.1688, lr_0 = 1.0000e-04\n",
      "Loss = 4.3949e-01, PNorm = 38.9401, GNorm = 3.6099, lr_0 = 1.0000e-04\n",
      "Loss = 4.0524e-01, PNorm = 38.9443, GNorm = 3.2041, lr_0 = 1.0000e-04\n",
      "Loss = 4.0051e-01, PNorm = 38.9478, GNorm = 1.6882, lr_0 = 1.0000e-04\n",
      "Loss = 4.3854e-01, PNorm = 38.9511, GNorm = 1.9671, lr_0 = 1.0000e-04\n",
      "Loss = 3.6071e-01, PNorm = 38.9549, GNorm = 2.2838, lr_0 = 1.0000e-04\n",
      "Loss = 4.2504e-01, PNorm = 38.9574, GNorm = 2.3171, lr_0 = 1.0000e-04\n",
      "Loss = 4.1415e-01, PNorm = 38.9616, GNorm = 2.2714, lr_0 = 1.0000e-04\n",
      "Loss = 3.9073e-01, PNorm = 38.9646, GNorm = 3.2347, lr_0 = 1.0000e-04\n",
      "Loss = 4.1516e-01, PNorm = 38.9682, GNorm = 2.3678, lr_0 = 1.0000e-04\n",
      "Loss = 3.9900e-01, PNorm = 38.9720, GNorm = 2.1224, lr_0 = 1.0000e-04\n",
      "Loss = 4.3129e-01, PNorm = 38.9759, GNorm = 1.3614, lr_0 = 1.0000e-04\n",
      "Loss = 4.2833e-01, PNorm = 38.9801, GNorm = 2.3050, lr_0 = 1.0000e-04\n",
      "Loss = 4.3867e-01, PNorm = 38.9841, GNorm = 1.6689, lr_0 = 1.0000e-04\n",
      "Loss = 3.9798e-01, PNorm = 38.9882, GNorm = 1.4382, lr_0 = 1.0000e-04\n",
      "Loss = 3.9119e-01, PNorm = 38.9919, GNorm = 2.5494, lr_0 = 1.0000e-04\n",
      "Loss = 4.4036e-01, PNorm = 38.9956, GNorm = 2.2443, lr_0 = 1.0000e-04\n",
      "Loss = 4.2811e-01, PNorm = 39.0000, GNorm = 1.3659, lr_0 = 1.0000e-04\n",
      "Loss = 4.3092e-01, PNorm = 39.0043, GNorm = 2.1394, lr_0 = 1.0000e-04\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [05:06<00:52, 17.38s/it]Epoch 17\n",
      "Loss = 3.3719e-01, PNorm = 39.0097, GNorm = 3.0845, lr_0 = 1.0000e-04\n",
      "Loss = 4.2610e-01, PNorm = 39.0134, GNorm = 2.5203, lr_0 = 1.0000e-04\n",
      "Loss = 4.7261e-01, PNorm = 39.0166, GNorm = 2.3985, lr_0 = 1.0000e-04\n",
      "Loss = 3.8454e-01, PNorm = 39.0209, GNorm = 2.8175, lr_0 = 1.0000e-04\n",
      "Loss = 3.9848e-01, PNorm = 39.0243, GNorm = 1.9937, lr_0 = 1.0000e-04\n",
      "Loss = 3.9375e-01, PNorm = 39.0281, GNorm = 1.4011, lr_0 = 1.0000e-04\n",
      "Loss = 4.2652e-01, PNorm = 39.0321, GNorm = 2.8534, lr_0 = 1.0000e-04\n",
      "Loss = 4.3552e-01, PNorm = 39.0365, GNorm = 4.3416, lr_0 = 1.0000e-04\n",
      "Loss = 4.2726e-01, PNorm = 39.0403, GNorm = 3.0906, lr_0 = 1.0000e-04\n",
      "Loss = 3.9365e-01, PNorm = 39.0449, GNorm = 2.3527, lr_0 = 1.0000e-04\n",
      "Loss = 3.8385e-01, PNorm = 39.0493, GNorm = 1.9669, lr_0 = 1.0000e-04\n",
      "Loss = 4.0302e-01, PNorm = 39.0535, GNorm = 3.4980, lr_0 = 1.0000e-04\n",
      "Loss = 4.1336e-01, PNorm = 39.0571, GNorm = 3.0824, lr_0 = 1.0000e-04\n",
      "Loss = 4.1003e-01, PNorm = 39.0602, GNorm = 2.4507, lr_0 = 1.0000e-04\n",
      "Loss = 3.9152e-01, PNorm = 39.0631, GNorm = 1.4463, lr_0 = 1.0000e-04\n",
      "Loss = 4.2319e-01, PNorm = 39.0663, GNorm = 1.9993, lr_0 = 1.0000e-04\n",
      "Loss = 4.1623e-01, PNorm = 39.0696, GNorm = 3.9793, lr_0 = 1.0000e-04\n",
      "Loss = 4.1542e-01, PNorm = 39.0730, GNorm = 2.8909, lr_0 = 1.0000e-04\n",
      "Loss = 3.5905e-01, PNorm = 39.0759, GNorm = 1.9071, lr_0 = 1.0000e-04\n",
      "Loss = 3.2340e-01, PNorm = 39.0791, GNorm = 2.5991, lr_0 = 1.0000e-04\n",
      "Loss = 3.9009e-01, PNorm = 39.0821, GNorm = 1.8032, lr_0 = 1.0000e-04\n",
      "Loss = 4.6556e-01, PNorm = 39.0851, GNorm = 2.2330, lr_0 = 1.0000e-04\n",
      "Loss = 4.4395e-01, PNorm = 39.0878, GNorm = 1.4861, lr_0 = 1.0000e-04\n",
      "Loss = 3.9192e-01, PNorm = 39.0920, GNorm = 3.6780, lr_0 = 1.0000e-04\n",
      "Loss = 4.0174e-01, PNorm = 39.0953, GNorm = 2.8193, lr_0 = 1.0000e-04\n",
      "Loss = 4.8755e-01, PNorm = 39.0971, GNorm = 1.9701, lr_0 = 1.0000e-04\n",
      "Loss = 4.2247e-01, PNorm = 39.0997, GNorm = 3.0571, lr_0 = 1.0000e-04\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [05:25<00:35, 17.88s/it]Epoch 18\n",
      "Loss = 5.5659e-01, PNorm = 39.1032, GNorm = 3.2681, lr_0 = 1.0000e-04\n",
      "Loss = 4.1761e-01, PNorm = 39.1073, GNorm = 2.1090, lr_0 = 1.0000e-04\n",
      "Loss = 4.1630e-01, PNorm = 39.1113, GNorm = 1.4632, lr_0 = 1.0000e-04\n",
      "Loss = 4.2039e-01, PNorm = 39.1145, GNorm = 2.4924, lr_0 = 1.0000e-04\n",
      "Loss = 3.8108e-01, PNorm = 39.1182, GNorm = 1.9164, lr_0 = 1.0000e-04\n",
      "Loss = 4.1060e-01, PNorm = 39.1220, GNorm = 3.0314, lr_0 = 1.0000e-04\n",
      "Loss = 4.0342e-01, PNorm = 39.1263, GNorm = 1.6734, lr_0 = 1.0000e-04\n",
      "Loss = 3.8121e-01, PNorm = 39.1298, GNorm = 1.6746, lr_0 = 1.0000e-04\n",
      "Loss = 4.2672e-01, PNorm = 39.1331, GNorm = 3.8536, lr_0 = 1.0000e-04\n",
      "Loss = 4.3746e-01, PNorm = 39.1367, GNorm = 2.9553, lr_0 = 1.0000e-04\n",
      "Loss = 4.1183e-01, PNorm = 39.1401, GNorm = 3.1768, lr_0 = 1.0000e-04\n",
      "Loss = 4.0331e-01, PNorm = 39.1423, GNorm = 3.8069, lr_0 = 1.0000e-04\n",
      "Loss = 4.1049e-01, PNorm = 39.1452, GNorm = 1.8727, lr_0 = 1.0000e-04\n",
      "Loss = 4.0143e-01, PNorm = 39.1492, GNorm = 2.2696, lr_0 = 1.0000e-04\n",
      "Loss = 3.9531e-01, PNorm = 39.1531, GNorm = 1.4897, lr_0 = 1.0000e-04\n",
      "Loss = 4.1480e-01, PNorm = 39.1571, GNorm = 2.3999, lr_0 = 1.0000e-04\n",
      "Loss = 4.3922e-01, PNorm = 39.1612, GNorm = 2.0601, lr_0 = 1.0000e-04\n",
      "Loss = 3.8985e-01, PNorm = 39.1651, GNorm = 1.2311, lr_0 = 1.0000e-04\n",
      "Loss = 3.8830e-01, PNorm = 39.1689, GNorm = 2.8597, lr_0 = 1.0000e-04\n",
      "Loss = 3.8117e-01, PNorm = 39.1725, GNorm = 1.7093, lr_0 = 1.0000e-04\n",
      "Loss = 4.0771e-01, PNorm = 39.1759, GNorm = 3.0175, lr_0 = 1.0000e-04\n",
      "Loss = 4.2191e-01, PNorm = 39.1794, GNorm = 2.6605, lr_0 = 1.0000e-04\n",
      "Loss = 3.8184e-01, PNorm = 39.1833, GNorm = 2.8618, lr_0 = 1.0000e-04\n",
      "Loss = 3.9628e-01, PNorm = 39.1873, GNorm = 3.2345, lr_0 = 1.0000e-04\n",
      "Loss = 3.9469e-01, PNorm = 39.1915, GNorm = 1.5484, lr_0 = 1.0000e-04\n",
      "Loss = 3.8781e-01, PNorm = 39.1948, GNorm = 2.7192, lr_0 = 1.0000e-04\n",
      "Loss = 4.1024e-01, PNorm = 39.1981, GNorm = 1.2645, lr_0 = 1.0000e-04\n",
      "Loss = 4.0159e-01, PNorm = 39.2014, GNorm = 2.2357, lr_0 = 1.0000e-04\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [05:42<00:17, 17.67s/it]Epoch 19\n",
      "Loss = 4.4379e-01, PNorm = 39.2045, GNorm = 1.9912, lr_0 = 1.0000e-04\n",
      "Loss = 4.4460e-01, PNorm = 39.2071, GNorm = 1.6137, lr_0 = 1.0000e-04\n",
      "Loss = 3.8371e-01, PNorm = 39.2099, GNorm = 2.1609, lr_0 = 1.0000e-04\n",
      "Loss = 4.2128e-01, PNorm = 39.2121, GNorm = 2.0595, lr_0 = 1.0000e-04\n",
      "Loss = 3.5328e-01, PNorm = 39.2152, GNorm = 2.0130, lr_0 = 1.0000e-04\n",
      "Loss = 4.2496e-01, PNorm = 39.2193, GNorm = 4.3595, lr_0 = 1.0000e-04\n",
      "Loss = 3.6276e-01, PNorm = 39.2240, GNorm = 2.1661, lr_0 = 1.0000e-04\n",
      "Loss = 3.6690e-01, PNorm = 39.2280, GNorm = 2.0488, lr_0 = 1.0000e-04\n",
      "Loss = 4.1850e-01, PNorm = 39.2318, GNorm = 2.1848, lr_0 = 1.0000e-04\n",
      "Loss = 4.1834e-01, PNorm = 39.2347, GNorm = 3.0337, lr_0 = 1.0000e-04\n",
      "Loss = 3.3737e-01, PNorm = 39.2372, GNorm = 1.6916, lr_0 = 1.0000e-04\n",
      "Loss = 3.8192e-01, PNorm = 39.2395, GNorm = 1.9404, lr_0 = 1.0000e-04\n",
      "Loss = 4.0841e-01, PNorm = 39.2434, GNorm = 1.9682, lr_0 = 1.0000e-04\n",
      "Loss = 3.8157e-01, PNorm = 39.2466, GNorm = 2.0104, lr_0 = 1.0000e-04\n",
      "Loss = 4.0930e-01, PNorm = 39.2496, GNorm = 4.0807, lr_0 = 1.0000e-04\n",
      "Loss = 4.0826e-01, PNorm = 39.2535, GNorm = 3.3138, lr_0 = 1.0000e-04\n",
      "Loss = 3.7021e-01, PNorm = 39.2567, GNorm = 1.4284, lr_0 = 1.0000e-04\n",
      "Loss = 4.0622e-01, PNorm = 39.2606, GNorm = 1.9263, lr_0 = 1.0000e-04\n",
      "Loss = 4.2851e-01, PNorm = 39.2637, GNorm = 1.3286, lr_0 = 1.0000e-04\n",
      "Loss = 3.9814e-01, PNorm = 39.2669, GNorm = 3.6324, lr_0 = 1.0000e-04\n",
      "Loss = 3.7976e-01, PNorm = 39.2707, GNorm = 1.7793, lr_0 = 1.0000e-04\n",
      "Loss = 4.1497e-01, PNorm = 39.2744, GNorm = 2.7514, lr_0 = 1.0000e-04\n",
      "Loss = 3.8710e-01, PNorm = 39.2784, GNorm = 2.4332, lr_0 = 1.0000e-04\n",
      "Loss = 3.5584e-01, PNorm = 39.2824, GNorm = 2.7339, lr_0 = 1.0000e-04\n",
      "Loss = 3.5540e-01, PNorm = 39.2859, GNorm = 1.6426, lr_0 = 1.0000e-04\n",
      "Loss = 3.7337e-01, PNorm = 39.2890, GNorm = 2.2621, lr_0 = 1.0000e-04\n",
      "Loss = 3.9300e-01, PNorm = 39.2924, GNorm = 1.3501, lr_0 = 1.0000e-04\n",
      "Loss = 3.9620e-01, PNorm = 39.2964, GNorm = 1.5788, lr_0 = 1.0000e-04\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [06:01<00:00, 18.05s/it]\n",
      "qsprpred - WARNING - Early stopping did not yield a best model, using last model instead.\n"
     ]
    }
   ],
   "source": [
    "from qsprpred.models import CrossValAssessor\n",
    "#, TestSetAssessor\n",
    "from qsprpred.models.early_stopping import EarlyStoppingMode\n",
    "\n",
    "# We can now assess the model performance on the training set using cross validation\n",
    "# CrossValAssessor(masked_metric, split_multitask_scores=True)(model, dataset)\n",
    "\n",
    "# and on the test set\n",
    "TestSetAssessor(masked_metric, split_multitask_scores=True)(model, dataset)\n",
    "\n",
    "# Finally, we need to fit the model on the complete dataset if we want to use it further\n",
    "# This will save the fitted model and metadata to disk\n",
    "model.earlyStopping.numEpochs = 20\n",
    "model.fitDataset(dataset, mode=EarlyStoppingMode.FIXED)\n",
    "\n",
    "# We can optionally save the model and metadata to disk explicitly as well\n",
    "_ = model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, \\\n",
    "    mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "# get independent test set\n",
    "df = pd.read_table(\n",
    "    \"/home/s2861704/ppk/test_kin/test_output/MT/models/ChempropMTTestModel/ChempropMTTestModel.ind.tsv\")\n",
    "\n",
    "# filling NaN-values with fillna() makes the code work, but results in the same issues imputation has. next step to try: individual target plotting\n",
    "# df = df.fillna(0)\n",
    "\n",
    "# column names containing original labels or predictions for the tasks\n",
    "label_names = [i for i in list(df.columns.values) if \"Label\" in i]\n",
    "pred_names = [i for i in list(df.columns.values) if \"Prediction\" in i]\n",
    "\n",
    "# turn into np array\n",
    "ylabel = df[label_names].to_numpy()\n",
    "ypred = df[pred_names].to_numpy()\n",
    "\n",
    "# get metrics\n",
    "summary = {}\n",
    "for metric in [explained_variance_score, mean_absolute_error, mean_squared_error,\n",
    "               r2_score]:\n",
    "    score = metric(ylabel, ypred)\n",
    "    summary[metric.__name__] = score\n",
    "\n",
    "summary[\"ModelName\"] = model.name\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_regression_MT import CorrelationPlot\n",
    "\n",
    "plot = CorrelationPlot([model])\n",
    "axes, summary = plot.make(save=True, show=True, out_path='/home/s2861704/ppk/test_kin/test_output/ChempropMT.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drugex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
